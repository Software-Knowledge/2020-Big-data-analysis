Lecture8-推荐系统
---

[TOC]

# 1. 引入:推荐系统的例子
1. 京东推荐系统
2. 推荐产品和食物
3. 两个客户:
   1. 客户X:购买了CD1和CD2
   2. 客户Y:搜索了CD1，那么推荐系统将会根据从客户X处收集到的信息推荐给客户CD2 

# 2. 推荐与推荐系统
> 用户执行物品搜索，推荐系统根据情况返回推荐结果

![](img/lec8/1.png)

## 2.1. 什么是推荐系统
1. 推荐系统是提供推荐给用户的系统
   1. 过多的信息(信息过载)
   2. 用户有太多的选择
2. 根据用户的口味，来推荐用户不同的商品
   1. 协助用户发现信息
   2. 减少搜索和导航的时间

## 2.2. 从稀缺到丰富
1. 货架空间是稀缺的传统商品零售商，同样的还有电视网络、电影院
2. Web使有关产品信息的成本接近零传播：从稀缺到丰富
3. 更多选择需要更好的过滤器：推荐引擎

| 长尾模式            | 实体和线上          |
| ------------------- | ------------------- |
| ![](img/lec8/2.png) | ![](img/lec8/3.png) |

## 2.3. 推荐分类
1. 编辑和策划
   1. 收藏夹列表
   2. "基本"项目清单
2. 简单的集合：前10名，最受欢迎，最近上传
3. 针对个人用户：亚马逊，Netflix等…

## 2.4. 推荐系统的一般模型
1. $X$是消费者集合
2. $S$是物品集合
3. 使用函数:$u: X * S \to R$
   1. $R$是评分集合
   2. $R$是一套完全有序的集合
   3. 比如，0-5星，0-1分
4. Utility Matrix

![](img/lec8/4.png)

## 2.5. 用户和物品的对比
![](img/lec8/21.png)

## 2.6. 个性化
1. 个性化:用户匹配系统
2. 交互式基于用户个人数据情况而个性化展开的
   1. 个性化网页
   2. 个性化指导
   3. 个性化推荐

## 2.7. 和BDA的联系
环境智能 = 普适计算 + 智能接口(比如个性化)

## 2.8. 用户信息
> 从简单到复杂
1. 人口统计学信息:年龄、性别、低于
2. 兴趣、偏好、专业级别
3. 购买记录、观察行为
4. 打分
5. ...
6. 计算生活日志

### 2.8.1. 用户信息的来源
1. 用户直接的输入(如调查问卷)
2. 通过系统非显式收集到
   1. 观察/记录用户行为
   2. 学习/推理用户的兴趣/偏好/级别
3. 集合使用所有的方法
4. 其他的维度:公有/私有

### 2.8.2. 用户信息的获取
1. 格式:
   1. 原数据
   2. 概括(发现模式 & 生成)
      1. 统计性机器学习方法
      2. 基于ML方法的知识
   3. 保持以上两种的方式(在时间上去重新学习或者适应)，保持原数据的有效时间
2. 其他人介入过程可能会导致信息的**误收集**，比如虽然你很喜欢，但是别人阻止了你，导致你知识很多次浏览，最终没有形成最后的购买行为。

## 2.9. 推荐过程中的关键问题
| 问题                     | 详细描述                                                                                           |
| ------------------------ | -------------------------------------------------------------------------------------------------- |
| **收集矩阵的"已知"评分**     | 如何收集Utility Matrix中的数据                                                                     |
| **从已知评级中推断未知评级** | 主要对高未知等级感兴趣，我们对了解自己不喜欢的东西并不感兴趣                                       |
| **评估外推方法**             | 如何衡量推荐方法的成功/绩效                                                                        |
| **冷启动问题**               | 对于长时间的系统没有影响，但是对于短时间(刚开始)的系统有着比较重要的预测作用                       |
| **完成模型转换**             | 用户往往没有直接的输入，不会直接表达兴趣                                                           |
| **模糊的信息**               | 比明确的资料要糟糕，有很多的用户、网页，并且用户的资料信息比较短                                   |
| **隐藏的网页**               | 在互联网部分很多的网页是通过数据库查询而获取的，其重要性很难通过日志显示出来，不能无差别的推荐物品 |

### 2.9.1. 用户评分的收集

#### 2.9.1.1. 显式收集
1. 最精确的评分:用户直接打分，通常使用1到5或者1到7的李克特反应量表
2. 相关研究
   1. 最佳粒度:表示10分制在电影中被更好地接受了。
   2. 在讨论的笑话推荐器中选择了更细粒度的制式
   3. Gold Berg等使用了连续刻度(从-10到+10)和图形输入栏
      1. 离散化不会造成精度损失
      2. 可以更精细地捕获用户首选项
      3. 用户实际上"喜欢"图形交互方法
   4. 多维等级(每部电影的多重等级，例如演员和声音的等级)
3. 主要问题
   1. **用户并不总是愿意为许多项目评分**：可用评分的数量可能太少`->`评分矩阵稀疏`->`推荐质量较差
   2. 如何刺激用户给更多物品评分？

#### 2.9.1.2. 非显式收集
1. 从用户行为中学习到评分
   1. 通常是通过嵌入了推荐系统的网上商店或应用程序收集
   2. 比如**客户购买行为**，许多推荐系统会解释为高评级(好评)
2. **评价指标**:点击次数、浏览量、在某些页面上花费的时间、下载量
3. 隐式评价可以不断收集，不需要用户方面的额外做什么
4. 主要问题
   1. 不能确定用户行为是否被正确解释
   2. 例如，用户可能不喜欢他或她购买的所有书籍；用户也可能已经为别人买了一本书
5. 除了显式的评价外，还可以使用隐式评价，但是往往是处于经验结论。

### 2.9.2. 从已知评级中推断未知评级
1. 核心问题:Utility Matrix是稀疏的
   1. 大多数用户不会给大多数物品打分，导致了很多的缺项
   2. 冷启动：新物品没有评分、新用户没有足迹
2. 实现推荐系统的三个方法
   1. 基于内容的推荐系统(多)
   2. 基于协同的推荐系统(多)
   3. 基于潜在因子的推荐系统

## 2.10. 网络个性化过程
1. 生成用户模型
   1. 使用的不是一个用户而是一个集群的用户
   2. 是一个离线过程
   3. 步骤
      1. 聚类用户交易行为等
      2. 聚类物品或页面浏览路径
      3. 关联挖掘规则
      4. 序列化发现模式
2. 提供推荐服务
   1. 在线过程
   2. 结合用户的动态进程，提供动态内容

| off-line             | on-line              |
| -------------------- | -------------------- |
| ![](img/lec8/20.png) | ![](img/lec8/55.png) |


## 2.11. 用户建模
1. 根据用户的应用和使用来划分用户模型：跨应用程序可重用
2. 大多数还是理论的，并不实际
3. 最新状态:每一个应用有他自己的用户模型来完成其特定的任务

# 3. 基于协同的推荐系统
1. 协同过滤:利用其他用户的数据来为用户完成推荐

## 3.1. 协同过滤过程
1. 我们考虑用户X
2. 查找评级与用户X评级"相似"的N个其他用户的集合
3. 根据N个用户的评分来估算X的评分，并决定是否推荐给用户X

![](img/lec8/6.png)

## 3.2. 协同过滤(Collaborative Filtering, CF)
1. 协同过滤是推荐的最杰出方法
   1. 由大型商业电子商务网站使用
   2. 很好理解，存在各种算法和变体
   3. 适用于许多领域(书籍，电影，DVD等)
2. 方法：使用"人群的智慧"推荐物品基本假设和想法
3. 假设：在用户通过隐式或显式的方式完成对目录项进行评分，并且过去口味相似的客户在未来也有大可能口味相似

## 3.3. 基于用户的最近邻协同过滤
1. 基本技巧：给定活跃用户X和用户X尚未看到的商品i
   1. 找到一组过去喜欢与X相同的商品并且对商品i进行了评分的用户Y(同龄人/最近的邻居)
   2. 使用推荐系统进行预测，例如预测用户X给商品i的评分会是多少
   3. 对用户X没看过的所有商品执行此操作，并给用户X推荐评分最高的商品
2. 基本假设和想法：如果用户过去具有相似的口味，将来他们也会具有相似的口味。用户偏好会随着时间的推移保持稳定和一致

### 3.3.1. 寻找相似的用户
1. 我们让$r_x$作为用户x的评分向量
2. Jaccard相似度
   1. $J(A,B) = \frac{|A\cap B|}{|A \cup B|}$
   2. 问题是忽略了评分的价值
   3. 我们把$r_x$和$r_y$作为集合
      1. $r_x = \{1, 4, 5\}$
      2. $r_y = \{1, 3, 4\}$
3. 余弦相似度:问题是把没有评分的部分作为负面情况
   1. $sim(x,y) = cos(r_x, r_y) = \frac{r_x * r_y}{||r_x||*||r_y||}$
   2. 我们把$r_x$和$r_y$作为点
      1. $r_x = \{1, 0, 0, 1, 3\}$
      2. $r_y = \{1, 0, 2, 2, 0\}$ 
4. 皮尔逊相关系数，$S_{xy}$指的是物品和用户x、y的相似性：$\overline{r_x}$和$\overline{r_y}$是x和y的均值评分

$$
sim(x,y) = \frac{\sum\limits_{s \in S_{xy}}(r_{xs} - \overline{r_x})(r_{ys} - \overline{r_y})}{\sqrt{\sum\limits_{s \in S_{xy}}(r_{xs} - \overline{r_x})^2 }\sqrt{\sum\limits_{s \in S_{xy}}(r_{ys} - \overline{r_y})^2}}
$$

### 3.3.2. 相似矩阵例子
![](img/lec8/7.png)

> 直观地我们想要说明:$Sim(A, B) > Sim(A, C)$

1. Jaccard相似度：$Sim(A, B) = \frac{1}{5} < Sim(A, C) = \frac{2}{4}$
2. 余弦相似度：$Sim(A, B) = 0.380 > Sim(A, C) = 0.322$
   1. 认为缺失的评分为0，问题:默认是负面评论
      1. A = {4, 0, 0, 5, 1, 0, 0}
      2. B = {5, 5, 4, 0, 0, 0, 0}
      3. C = {0, 0, 0, 2 ,4 ,5, 0}
      4. $Sim(A, B) = 0.380 > Sim(A, C) = 0.322$
   2. 解决默认负面评论：减去(行)平均值，$Sim(A, B) =  0.092 > Sim(A, C) = -0.559$

![](img/lec8/8.png)

## 3.4. 评分预测
1. 从相似性指标到推荐：
   1. 设$r_x$为用户x评分的向量
   2. 设N为与x最相似的，对项目i评分的k个用户的集合
   3. 对用户x的项目s的预测：($S_{xy}$是$sim(x,y)$的缩写)
2. 以下为几种分数预测策略：

$$
\begin{array}{l}
   r_{xi} = \frac{1}{k}\sum\limits_{y\in N} r_{yi} \\
   \ \\
   r_{xi} = \frac{\sum\limits_{y\in N}s_{xy} * r_{yi}}{\sum\limits_{y\in N} s_{xy}}
\end{array}
$$

## 3.5. 物品-物品协同过滤
1. 到目前为止：我们完成了用户-用户的协作过滤
2. 但是我们还有另一种角度：物品
   1. 对于物品i，找到其他类似的物品
   2. 根据类似物品的评级估算物品i的评级
   3. 可以使用与用户-用户模型相同的相似性指标和预测功能

$$
r_{xi} = \frac{\sum\limits_{j \in N(i; x)} s_{ij} * r_{xj}}{\sum\limits_{y \in N(i; x)}S_{ij}}
$$

1. $s_{ij}$是物品i和j之间的相似度
2. $r_{xj}$是用户x对物品j的评分
3. $N(i;x)$是设置由用户x评分与i相似的项目

### 3.5.1. 物品-物品协同过滤的例子

| ![](img/lec8/9.png)  | ![](img/lec8/10.png) |
| -------------------- | -------------------- |
| ![](img/lec8/11.png) | ![](img/lec8/12.png) |
| ![](img/lec8/13.png) |                      |

### 3.5.2. 更加普遍的协同过滤
- 我们定义项$i$和$j$的相似度为$s_{ij}$
- 选择k个最近的邻居$N(i; x)$:与用户$x$最相似的项目，由用户$x$评分
- 将等级$r_{xi}$估计为加权平均值：

$$
\begin{array}{l}
   Before:r_{xi} = \frac{\sum\limits_{y\in N}s_{xy} * r_{yi}}{\sum\limits_{y\in N} s_{xy}} \\
   \ \\
   After: r_{xi} = b_{xi} + \frac{\sum\limits_{j \in N(i; x)} s_{ij} * (r_{xj} - b_{xj})}{\sum\limits_{j \in N(i; x)}s_{ij}} \\
   \ \\
   b_{xi} = \mu + b_x + b_i
\end{array}
$$

- $\mu$:电影整体平均收视率
- $b_x$:用户x的评分偏差 = (用户x的平均评分)- $\mu$
- $b_i$:电影i的评分偏差

## 3.6. 对于物品-物品的协同过滤和用户-用户的协同过滤
> 在实际生活中，我们可以观察到物品-物品通常比用户-用户更好地工作
> 因为物品更简单，而用户有很多的口味

![](img/lec8/14.png)

## 3.7. 数据稀疏性问题
1. 冷启动问题：如何推荐新商品？向新用户推荐什么？
2. 直接的方法
   1. 要求/强迫用户对一组项目进行评分
   2. 在初始阶段使用另一种方法(例如，基于内容的，人口统计学的或只是非个性化的)
   3. 默认投票：为只有两个要比较的用户之一进行评分的项目分配默认值(Breese等，1998)
3. 备择方案
   1. 使用更好的算法(超越最近的邻域方法)
   2. 例：
      1. 在最近邻居方法中，足够相似的邻居的集合可能太小而无法做出好的预测
      2. 假设邻居的"传递性"

## 3.8. 协同过滤的优点
> 适用于任何种类的物品：无需选择功能

1. 隐式收集:不需要明确的用户打分和用户交互
2. 大量数据:使用不同的数据来保护用户隐私
3. 如果我们大规模地使用户数据，那么协同过滤更加有效。
4. 基于内容、知识的推荐方法是很难使用在网络数据上

## 3.9. 协同过滤的缺点
1. 冷启动：系统中需要足够的用户才能找到匹配项
2. 稀疏度：
   1. 用户/评分矩阵稀疏
   2. 很难找到评分相同的用户
3. 最初评分：
   1. 无法推荐以前未评级的项目
   2. 新项目，神秘项目
4. 人气偏见：
   1. 无法向有独特品味的人推荐产品
   2. 倾向于推荐热门商品

# 4. 基于内容的推荐系统
1. 核心思想:向用户推荐他自己之前高度评价相似的商品
2. 例子:
   1. 电影推荐:推荐由相同演员、导演和主演的电影
   2. 网络、博客和新闻:推荐由相似内容的其它网站

## 4.1. 基于内容的推荐系统概述
1. 协同过滤方法不需要有关项目的任何信息
   1. 利用此类信息可能是合理的
   2. 向过去喜欢幻想小说的人推荐幻想小说
2. 我们需要什么：
   1. 有关可用项目的一些信息，例如类型("内容")
   2. 描述用户喜欢的某种用户配置文件(首选项)
3. 任务：
   1. 了解用户偏好
   2. 查找/推荐与用户首选项"相似"的项目

![](img/lec8/35.png)

## 4.2. 推荐过程
> 对于文本信息提取的时候会使用到TF-IDF算法

![](img/lec8/5.png)

## 4.3. 物品资料
1. 为每个物品创建一个物品资料
2. 物品资料是一组特征(向量)
   1. 电影：作者，标题，演员，导演，…
   2. 文本：文档中的一组"重要"词
3. 如何选择重要功能？以文本挖掘为例，我们通常使用启发式方法为TF-IDF算法
   1. 词：功能
   2. 文档：项目

## 4.4. 用户资料
1. 用户资料的可能形式
   1. 特定物品资料的加权平均值
   2. 差异：权重与平均评分的差异
2. 预测启发式：给定用户资料x和项目资料i，估算余弦相似度为$u(x,i) = cos(x,i) = \frac{x*i}{||x|| * ||i||}$

## 4.5. 基于内容方法的优点
1. 无需其他用户的数据：无冷启动或稀疏问题
2. **可以向口味独特的用户推荐**
3. **可以推荐不受欢迎的新商品**
4. 能够提供**解释**：可以通过列出导致推荐项目的内容功能来提供推荐项目的说明
5. 需要设置衰减机制来模拟喜好的变更

## 4.6. 基于内容方法的缺点
1. 很难找到合适的功能：例如图像，电影，音乐
2. 对新用户的建议：如何建立用户档案？
3. **过度专业化**
   1. 绝不推荐用户资料之外的项目
   2. 人们可能有多种兴趣
   3. 无法利用其他用户的质量判断

## 4.7. 讨论和总结
1. 与基于协同过滤的推荐方法相反，基于内容的推荐方法不需要用户数据即可工作
2. 提出的方法旨在基于**显式或隐式反馈**来学习用户兴趣偏好的模型：从用户行为中获取隐式反馈可能会出现问题
3. 评估表明，借助机器学习技术可以实现良好的推荐准确性：这些技术不需要用户社区
4. 存在推荐列表包含太多相似物品的危险
   1. 所有学习技术都需要一定数量的训练数据
   2. 一些学习方法倾向于过度拟合训练数据
5. 在商业环境中很少发现基于纯内容的系统

# 5. 基于知识的推荐系统
> 往往是基于情景或者限制条件

## 5.1. 基本的I/O关系
1. 基于知识的推荐系统:会告诉用户为什么会推荐给你这个

![](img/lec8/22.png)

## 5.2. 为什么我们需要基于知识的推荐系统
1. 可用评分较低的产品：也就是可能其他用户都不喜欢，但是你可能会喜欢。
2. **时间跨度**起着重要作用:时间变化会影响用户的口味
  1. 五年的计算机评级
  2. 用户生活方式或家庭情况的变化
3. 客户想要明确定义他们的需求："汽车的颜色应该是黑色的"

## 5.3. 基于知识的推荐系统的分类
1. 基于约束
   1. 基于明确定义的推荐规则
   2. 履行推荐规则
2. 基于案例
   1. 基于不同类型的相似性度量
   2. 检索与指定要求相似的物品
3. 两种方法的推荐过程相似
   1. 用户指定要求
   2. 系统尝试确定解决方案
   3. 如果找不到解决方案，则需要用户自行更改要求

## 5.4. 基于约束的推荐系统
1. 基于知识
   1. 通常在用户模型和物品属性之间进行折中
   2. 变量：用户模型功能(需求)，物品功能(目录)
   3. 约束集
      1. 逻辑含义(如果用户要求A，那么建议的物品应具有特征B)
      2. 硬约束和软约束/加权约束
      3. 解决方案偏好
2. 得出一组推荐项
   1. 满足一系列适用约束
   2. 约束的适用性取决于当前的用户模型
   3. 概要-推理的透明线

### 5.4.1. 基于约束的推荐任务
1. 查找一组用户要求，以使一部分物品满足所有约束：询问用户应该放宽/修改哪些要求，以使某些物品不违反任何约束条件
2. 查找满足加权约束最大集的物品子集：
   1. 类似于查找最大后继子查询(XSS)
   2. 所有推荐的物品都必须满足相同的约束条件
   3. 根据预定的权重计算缓冲区
3. 根据满足的软约束权重对项目进行排名
   1. 根据满足的比率对项目进行排序
   2. 不需要额外的排名方案

### 5.4.2. 基于约束的推荐系统问题
1. 从一个分类中选择出符合用户要求的一个产品

![](img/lec8/33.png)

2. 用户的要求一般会用自然语言进行描述，例子如下
   1. 价格应该比300块钱低
   2. 相机应该能够适用于运动摄影
3. 核心是我们如何将自然语言转化为几个关键词

### 5.4.3. 满足约束的问题
1. 具有陈述性知识表示的基于知识的RS，$CSP(X_1 \cup X_U,D,SRS \cup KB \cup I)$
2. 定义
   1. $X_j, X_U$:描述具有域D的产品和用户模型的变量
   2. KB：具有域限制的知识库
   3. SRS：用户的特定要求
   4. l：产品目录
3. 解决方案:满足您的要求$\theta\ \forall x \in X_1 (x = v) \in \theta \cap \in dom(x)\ s.t.\ SRS \cup KB \cup I \cup \theta$(令人满意)

### 5.4.4. 连接查询
1. 与约束求解器不同:它不是为CSP找到有效的实例
2. 连接查询在物品目录中执行。
   1. 联合数据库查询
   2. 一组连接在一起的选择标准
3. $O[criteria] P$
   1. P：产品分类
   2. 例如：$\delta[mpix210，pic30-0](P)= {p4，p7}$

### 5.4.5. 和基于约束的推荐者进行交互
1. 用户明确了他或她最初的偏好
   1. 一次全部指出
   2. 以向导的方式完成
   3. 对话交互
2. 一组符合的物品被展示给用户：一般会有为什么会推荐这个物品给用户的解释
3. 用户可能会修改他或她的需求
   1. 查看可替代的解决方案
   2. 缩小满足条件的物品的数量

### 5.4.6. 默认值
1. 支持用户选择有合理的替代方案
   1. 支持客户选择合理的替代方案。 不确定选择哪个选项
   2. 根本不知道技术细节
2. 默认类型
   1. 静态默认值
   2. 依赖默认值
   3. 派生的默认值
3. 选择下一个问题
   1. 大多数用户对指定所有属性的值不感兴趣
   2. 识别用户可能感兴趣的属性

### 5.4.7. 找不到满足要求的结果
1. 找不到解决方案
2. 放松约束条件
   1. 目的是确定对原始约束的放宽
   2. 放宽推荐问题的约束，直到找到相应的解决方案
3. 用户也可能对替换建议感兴趣：推荐者可以通过适应提意见的要求来计算解决方案

### 5.4.8. 处理不满足的要求
- 计算并诊断不满足的要求

![](img/lec8/43.png)

- 诊断从冲突集合中派生出来：${CS, CS, CS}$是{d:{r, r}, d:{r, r}, d:{r, r}}

## 5.5. 基于案例的推荐系统
1. 使用相似性度量检索项。
2. 距离相似性

$$
similarity(P, REQ) = \frac{\sum\limits_{r \in REQ} w_i * sim(p, r)}{\sum\limits_{r \in REQ w_r}}
$$

3. 定义:
   1. `sim(p，REQ)`表示每个商品属性值$\phi(p)$与客户需求的距离$r \in REQ$
   2. w是要求r的重要性权重
4. 在现实世界中，客户希望
   1. 最大限度地利用某些属性。例如，越多越好(MIB)
   2. 最小化某些属性。例如相机的价格，少即好(Lib)

### 5.5.1. 与基于案例的推荐者进行交互
1. 客户可能不知道他们在寻找什么
2. 标记(收藏)是支持此类导航的有效方法
3. 客户指定其当前物品(输入物品)无法满足的更改请求(价格或mpix)

![](img/lec8/44.png)

### 5.5.2. 多标记(收藏)
- 操作多个属性可以提高推荐对话框的效率

![](img/lec8/45.png)

## 5.6. 动态标记
1. 关联规则挖掘
2. 动态标记的基本步骤
   1. $q$：最初的一组要求
   2. $CI$：所有可用项目
   3. $K$：复合评论的最大数量
   4. $\sigma_{min}$：计算的关联规则的最小支持值。

![](img/lec8/57.png)


### 5.6.1. 示例：销售对话金融服务
1. 在金融服务领域
   1. 销售代表不知道应该推荐哪些服务
   2. 提高销售代表的整体生产力
2. 类似于呼叫中心脚本
   1. 最佳实践销售对话
   2. 状态，谓词的过渡
3. 研究成果：支持KA和验证，节点属性(可达，可扩展，确定性)

![](img/lec8/46.png)

### 5.6.2. 示例:标记
1. 项目空间中基于相似度的导航
2. 复合标记
   1. 比单元批判更有效的导航
   2. 频繁模式的挖掘
3. 动态标记：仅提出适用的复合标记
4. 渐进标记：考虑历史
5. 适应性建议：建议可以最优化用户偏好模型的项目

![](img/lec8/56.png)

## 5.7. 总结
1. 基于知识的推荐系统可以分为以下两部分
   1. 基于约束的推荐系统
   2. 基于案例的推荐系统
2. 约束
   1. 知识获取的代价
      1. 从领域专家获取
      2. 从用户获取
      3. 从网络资源获取
   2. 推荐模型的准确性
      1. 非常精细的偏好模型需要交互多次
      2. 协同过滤模型隐式偏好
3. 独立性假设可能会受到挑战：偏好并不总是彼此独立的

# 6. 混合推荐系统

## 6.1. 混合推荐系统引入
1. 实施两个或更多不同的推荐人并结合预测：也许使用线性模型
2. 将基于内容的方法添加到协作过滤中
   1. 新物品问题的物品资料
   2. 应对新用户问题的人口统计数据

![](img/lec8/41.png)

## 6.2. 混合推荐系统概述
1. 混合推荐系统：混合了多种输入或者结合不同的机制
   1. 协同过滤：告诉我在我的相似同类中他们喜欢的是什么
   2. 基于内容：展示给我还会继续喜欢的一类东西
   3. 基于知识：告诉我什么满足我现在的需求
2. 所有三个基本技术均由优秀的销售助理(销售行为的不同阶段)完美地合并在一起，但有其缺点，例如冷启动问题
3. 跨越两个(或多个)类型/实现的想法
   1. hybrida[lat.]：表示通过组合两个不同元素制成的对象
   2. 避免某些缺点
   3. 达到亲本个体不存在(或仅不一致)的理想特性
4. 不同的混合设计
   1. 并行使用多个系统
   2. 整体开发的不同功能
   3. 管道调用不同的系统：输入作为输出

### 6.2.1. 单一混合设计
1. 只有一个简单的推荐组件

![](img/lec8/42.png)

2. 混合是虚拟的，因为不同范式的特征/知识源已组合在一起

#### 6.2.1.1. 单一混合设计：特征合并
1. 多种知识来源的合并：比如评分、人口统计学信息或明确描述的需求，并且需要被应用到相似度计算上去
2. 混合内容特征
   1. 社交特征：被用户喜欢的电影
   2. 内容特征：被用户喜欢的戏剧，被用户喜欢的喜剧
   3. 混合特征：用户喜欢很多喜剧电影
3. 结合知识工程的努力，其中涉及发明良好的功能以实现成功的学习

#### 6.2.1.2. 单一混合设计：特征扩充
1. 内容驱动的协同过滤
   1. 例如，爱丽丝喜欢物品1和3(单维度评级)
      1. 物品7与1和3相似度为0.75
      2. 爱丽丝喜欢物品7的可能为0.75
   2. 物品矩阵变得稀疏
   3. 重要性加权和调整因子
      1. 同等物品的同行更重要
      2. 如果自己的评分更高，则对基于内容的预测的置信度更高。
2. 对研究论文的推荐，引用被解释为协同推荐

### 6.2.2. 并行混合设计
1. 输出是几种已经存在的实现的合并
2. 最低侵入性设计
3. 有些是权重或者投票的模型
   1. 权重会被动态学习到
   2. 动态加权的极端情况正在改变

![](img/lec8/47.png)

#### 6.2.2.1. 并行混合设计：加权
1. 根据权重计算和:$rec_{weighted}(u, i) = \sum\limits_{k=1}\limits^n\beta_k * rec_k(u, i)$

![](img/lec8/58.png)

2. 我们如何生成权重
   1. 经验引导
      1. 需要历史数据
      2. 计算不同的权重
      3. 确定哪一个人是最好的
   2. 动态调整权重
      1. 从均匀分布的权重开始
      2. 对每个用户，调整权重以最大化地减少预测误差
3. 假设爱丽丝实际上购买/点击了项目1和4:确定最小化平均绝对误差(MAE)的权重
4. 随着rec2的权重增加，MAE会提高

$$
MAE = \frac{\sum\limits_{r_i \in R }\sum\limits_{k = 1}\limits^n \beta_k * |rec_k(u, i) - r_i|}{|R|}
$$

> 下图中左侧红色框是权重，右侧红色框是MAE

![](img/lec8/59.png)

- 但是：res1是不是实际上将物品1和4的排名提高了？
- 加权时要小心！
  - 推荐者需要为所有用户和项目分配可比分数
  - 可能需要对分数进行转换
- 稳定的权重需要多个用户评价，而不是一个或者两个

![](img/lec8/60.png)

#### 6.2.2.2. 并行混合设计:转换
- 需要一个决定推荐人的决定

$$
\exists_1 k:1...n\ rec_{switching}(u, i) = rec_k(u, i)$$

- 动态权重的特殊情况(除了一个Beta为0以外，所有其他值)
- 例如：
  - 根据一些质量标准订购推荐产品并进行转换，例如：如果系统中的评分太少，则使用基于知识的评分，否则进行协作
  - 基于上下文参数的更复杂条件，应用分类技术

#### 6.2.2.3. 并行混合设计：混合
1. 根据用户接口的级别混合不同推荐系统的结果
2. 不同技术的结果被一并表示
3. 用户u和物品i的推荐结果是为其n个构成推荐者的每个元组`<score, k>`的集合

$$
rec_{mixed} =\bigcup_{k = 1}^n<rec_k(u, i), k>
$$

### 6.2.3. 管道混合设计
1. 一个推荐系统预处理一些输入在子过程中完成
   1. 级联：重定义推荐名单，逐步求精
   2. 元数据：学习模型

![](img/lec8/48.png)

#### 6.2.3.1. 管道混合设计：级联级别
1. 成功的推荐会被预处理其限制

$$
rec_{cascade}(u, i) = rec_u(u, i)
$$

2. 对于所有的k > 1

$$
rec_k(u,i) = \begin{cases}
   rec_{u, i}: rec_{k - 1} \neq 0\\
   0: otherwise \\
\end{cases}
$$

3. 后续推荐者可能不会引入其他项目，从而产生非常精确的结果
4. 推荐清单不断减少第一推荐人排除项目：删除绝对不可行的项目(例如基于知识的项目)
5. 第二推荐者分配分数：排序和完善(例如协作)

![](img/lec8/61.png)

#### 6.2.3.2. 管道混合设计：元数据级别
1. 成功的推荐会被预处理其限制

$$
rec_{meta-level}(u, i) = rec_{n}(u, i, \triangle_{rec_{n-1}})
$$

- 例子：Fab:
   - 在线新闻领域
   - CB推荐器基于加权术语向量构建用户模型
   - 协同过滤根据这些用户模型识别相似的对等方，但根据评分提出建议
- 基于协作约束的元级推荐系统
  - 协同过滤学习约束基础
  - 基于知识的推荐系统计算建议

## 6.3. 混合策略的限制
- 从元视角比较策略的推荐系统寥寥无几
  - 大多数数据集不允许比较不同的推荐范例
  - 即仅在单个数据集中很少提供的评分、要求、项目功能、领域知识、评论
  - 因此，很少有经验结论支持的结论
    - 整体式：以一些预处理工作为代价以换取更多知识
    - 并行式：需要仔细匹配来自不同预测变量的得分
    - 流水线：适用于两种对立的方法
- Netflix竞赛："堆叠"推荐系统
  - 基于>100个预测变量的加权设计：推荐功能
  - 基于用户模型，上下文和元功能的权重自适应切换

# 7. 可解释性

## 7.1. 推荐系统的解释动机
1. 数码相机对您来说是必买的，因为...
2. 推荐系统为什么要完全处理解释？
   1. 答案与提供和接收建议的两方有关
   2. 卖方可能对促销特定产品感兴趣"买方担心做出正确的购买决定

## 7.2. 推荐系统的解释分类
1. **功能性**：Rising-Sun品牌的Jumbo-Family-Vvan汽车类型非常适合您的家庭，因为您有四个孩子，汽车有七个座位。
2. **因果上**：灯泡亮是因为您打开了它。
3. **固定的**：我洗碗是因为我哥哥上次洗碗了、你必须做功课，因为你父亲这么说。
4. **科学的解释**：表达了在各个科学领域制定的概念之间的关系，并且通常基于可辩驳的理论

## 7.3. 什么是推荐系统的解释？
- 解释一些目标后系统输出的其他信息

![](img/lec8/49.png)

## 7.4. 提供解释的目的
1. 前述产生解释的目的可以相互关联
2. 说服力+`->`信任-
3. 有效性+`->`信任+

### 7.4.1. 透明度
1. 提供信息，以便用户理解
2. 提供关于为何一项优先于另一项的说明

### 7.4.2. 可靠性
1. 给用户检查推荐的可靠性
2. 不一定与透明度有关。例如，神经网络(NN)决定产品符合要求。 透明地公开NN的计算将无济于事，但是通过比较所需功能和提供的产品功能，客户可以判断建议的质量

### 7.4.3. 诚信度
1. 建立信任可以被视为减少不确定情况下人类决策复杂性的一种机制
2. 减少建议质量的不确定性

### 7.4.4. 说服力
1. 对建议的有说服力的解释旨在改变用户的购买行为
2. 例如，推荐人可能故意关注产品的正面方面，并对各种负面方面保持沉默

### 7.4.5. 有效期
1. 用户获得的高质量决策支持
2. 帮助客户发现他或她的喜好
3. 帮助用户做出更好的决定

### 7.4.6. 效率
1. 减少决策工作量
2. 减少决策所需的时间
3. 另一个措施也可能是认知努力

### 7.4.7. 满意
通过使用推荐系统提高总体满意度

### 7.4.8. 相关性
1. 对话推荐者可能需要其他信息
2. 可以提供解释以说明为什么需要用户提供其他信息的理由

### 7.4.9. 可理解性
1. 推荐人永远无法确定其用户的知识
2. 通过将用户的已知概念与推荐者采用的概念相关联来支持用户

### 7.4.10. 教育性
1. 教育用户以帮助他们更好地了解产品领域
2. 对领域的深入了解可帮助客户重新考虑自己的偏好，并评估不同解决方案的利弊
3. 最终，随着客户的了解越来越多，他们能够做出更明智的购买决定

## 7.5. 总体解释
- 如何、为什么？使用专家系统解释
- 归纳整理的形式
   - 给定$KB \rightarrow_{RS} i$，表示物品i被推荐系统RS使用方法推荐了
   - 找到$KB' \subseteq KB s.t. KB' \models_{RS} i$
- 简洁的原理:对于**最小**集合$KB' \subseteq KB s.t. KB' \not\models_{RS} i$
- 但是添加过滤：与扣除有关的某些部分对于人类可能是显而易见的

![](img/lec8/50.png)

## 7.6. 用于在推荐系统中生成解释的分类法
> 当前解释组件的主要设计维度
1. 生成的推理模型的类别
   1. 白盒
   2. 黑盒
2. 推荐系统用于生成解释的范例：决定容易丢失的语义
3. 信息类别

![](img/lec8/51.png)

## 7.7. KB的原型
1. 对象类别
   1. 用户
   2. 项目
   3. 属性
2. 他们之间的N元关系
3. 协同过滤
   1. 基于邻域的CF(a)
   2. 矩阵分解(b):引入其他因素代理来确定相似性

![](img/lec8/62.png)

## 7.8. 示例
1. 项目之间的相似性
2. 用户之间的相似性
3. 标签
   1. 标签相关性(针对项目)
   2. (用户的)标签首选项

## 7.9. 基于协同过滤的推荐系统的解释
1. 没有明确的推荐知识
2. 基于协同过滤的推荐无法提供关于为何产品适合客户或者为什么产品不符合客户要求的解释
3. 协同过滤的基本思想是模仿人类口碑推荐过程
4. 因此，请全面了解此口碑传播方法的工作原理：
   1. 客户评价产品
   2. 将具有相似等级(即口味)的顾客称为邻居
   3. 未通过客户评级的产品通过结合客户邻居的评级来评级

## 7.10. 评估说明接口
1. Herlocker等检查了MovieLens系统域中解释接口的各种实现方式
2. 评估了21个辩题
3. 顾客以1到7的比例被问及，通过二十一种不同的解释方法之一介绍并解释了这部电影的推荐后，他们去看推荐电影的可能性有多大
4. 他们还包括没有提供其他解释数据的基本案例。
5. 除基本情况外，还设计了一个解释界面，该界面仅输出推荐系统的过往性能：例如，在过去的80％的时间内，MovieLens为您提供了精确的报价

## 7.11. Herlocker的研究结果
- 最佳解释界面基于邻居的等级
- 在这些情况下，相似的邻居喜欢推荐的影片，并且这部影片的介绍很深刻。直方图的表现优于表格

![](img/lec8/63.png)

- 推荐人使用有关MovieLens过去表现的简单陈述获得第二好的表现
- 与内容相关的论点提到与其他高评价电影或喜欢的男演员或女明星的相似性，是表现最佳的演员
- 即使与基本案例相比，不良的解释界面设计也降低了客户遵循建议的意愿
- 信息过多会产生负面影响；通过将直方图中显示的数据与有关邻居的邻近性的信息进行混合来实现较差的性能
- 有趣的是，由电影评论家等领域权威机构提供评级的推荐建议并没有增加接受度

## 7.12. 基于案例的推荐系统的解释
1. 通过确定最适合客户查询的产品来实现基于案例的建议中解决方案的生成
2. 产品数据库的每个物品对应一个案例
3. 客户查询限制了物品的属性，例如，客户只对价格低于一定金额的数码相机感兴趣

## 7.13. 基于约束的推荐系统的解释
1. 回答客户可能提出的两个典型问题(Buchanan和Shortliffe 1984)
2. 为什么解释？如果推荐过程需要客户的输入，则客户可以问为什么需要此信息
3. 解释？当推荐人提出一套解决方案(例如产品)时，客户可能会要求解释为什么提出的解决方案对他或她有利
4. 接下来，我们通过利用基于约束的系统的推理方法来研究回答这两种类型问题的方法

## 7.14. 汽车领域的例子
1. 两种不同的包装可供汽车使用
   1. 商务套餐
   2. 娱乐套餐
2. 客户基于以下功能表达要求：轻松停车，拖曳和免提移动通信
3. 客户可以决定是否要使用其中一个，两个或两个都不包装
4. 休闲套餐
   1. 包括用于拖曳拖车的连接装置和位于汽车后部的摄像机，使驾驶员能够确定到汽车后面障碍物的距离
   2. 本相机支持以客户为导向的产品功能，易于停车
5. 商务套餐
   1. 包括带有GSM电话的收音机(GSM收音机)，支持免提移动通信
   2. 在后保险杠中包括一个传感器系统，该系统还支持轻松停车
   3. 但是，由于技术原因，传感器系统与娱乐套件不兼容
   4. 从客户的角度来看，摄像机和传感器系统提供相同的功能。因此，如果客户订购商务套票和休闲套票，则该汽车包括摄像机，该摄像机实现了便捷的停车功能
   5. 在这种配置中，不仅禁止使用传感器(因为它们与耦合设备不兼容)，而且还可以免除

## 7.15. 推荐系统解释性总结
1. 解释可以有多种类型，并且可以实现各种目标
2. 可以产生哪种类型的解释很大程度上取决于所采用的推荐方法
3. 解释可以用来塑造顾客的愿望和愿望，但它是一把双刃剑。
   1. 一方面，解释可以帮助顾客做出明智的购买决定
   2. 另一方面，可以滥用解释将客户推向仅对卖方有利的方向
4. 因此，对说明的深入理解和他们对客户的关注引起了极大的兴趣。

# 8. 度量与评估

## 8.1. 评估推荐系统
1. 评估推荐系统
   1. 已经提出了无数种技术，但是在给定的应用程序域中哪一个最好？
   2. 不同技术的成功因素是什么？基于最优准则的比较分析？
2. 研究问题是：
   1. 相对于特定标准(例如准确性，用户满意度，响应时间，偶然性，在线转换，加速工作等)，Isa RS效率很高。
   2. 顾客喜欢/购买推荐商品吗？
   3. 客户是否会购买原本不会购买的商品？
   4. 购买后是否满意推荐？

## 8.2. 实证研究
> 表征尺寸：

1. 谁是研究的重点对象？
2. 采用了哪些研究方法？
3. 研究在哪个背景下进行？

| 学科     | 在线客户，学生，基于足迹的在线进程、计算机 |
| -------- | ------------------------------------------ |
| 研究方法 | 实验，准实验，非实验研究                   |
| 设置     | 实验室，真实场景                           |

## 8.3. 评估设置
1. 实验室研究
   1. 专为研究目的而创建
   2. 通过选择研究参与者，可以更轻松地控制外部变量，但是对于金钱或奖品激励的参与者可能存在疑问
   3. 参与者的行为应与现实环境中的行为一样
2. 实地研究
   1. 在预先存在的真实环境中进行
   2. 激发用户使用系统的内在动力

## 8.4. 研究方法：实验与非实验(观测)研究方法
1. 实验(测试，试验)：
   1. 一项实验是对至少一个变量进行操作并将单位随机分配给不同级别或类别的受控变量的研究。
   2. 单位：用户，历史数据
   3. 控制变量：推荐系统类型、推荐一组物品、解释策略
2. 控制变量类别：基于内容的推荐系统，基于协同过滤的推荐系统

## 8.5. 实验设计

![](img/lec8/52.png)

## 8.6. 信息检索(IR)中的评估
1. 克兰菲尔德历史藏品(1950年代末)
   1. 1,398篇期刊摘要
   2. 225个查询
   3. 详尽的相关性判断(超过30万)
2. 人类领域专家建立的地面真理

![](img/lec8/53.png)

## 8.7. 指标:准确率和回归率
1. 推荐被视为信息检索任务：检索(推荐)所有预计为"良好"的物品。
2. 精度：精确度的度量，确定所检索到的相关项目在所有检索到的项目中所占的比例：例如，推荐的电影中实际上很不错的比例

$$
Precision = \frac{tp}{tp + fp} = \frac{|被推荐的好电影|}{|所有被推荐的|}
$$

召回：完整性的度量，确定所有相关项目中相关项目的分数:例如，所有推荐的好电影的推荐

$$
Recall = \frac{tp}{tp + fn} = \frac{|被推荐的好电影|}{|所有好电影|}
$$

- 通常，当调整推荐系统以提高准确性时，召回率因此降低(反之亦然)

![](img/lec8/64.png)

## 8.8. $F_1$度量
1. $F_1$指标尝试将Precision和Recall合并为一个值以进行比较:可用于获得更平衡的性能视图

$$
F_1 = 2 * \frac{precision * recall}{precision + recall}
$$

2. $F_1$指标对精度和召回率给予同等的重视:其他$F_\beta$指标的权重召回系数为$\beta$。

## 8.9. 指标：排名很重要

![](img/lec8/54.png)

> 排名指标可提高召回率和准确性，以考虑排名列表中正确项目的位置
1. 相关项物品在推荐列表中较早出现时会更有用
2. 在推荐系统中尤为重要，因为排名较低的物品可能会被用户忽略

## 8.10. 推荐系统中的评估
1. 带有用户评分项目的数据集：
   1. MovieLens数据集100K 10M评级
   2. Netflix 100M评级
2. 历史用户评级构成了基本事实
3. 指标衡量错误率
   1. 平均绝对误差(MAE)计算预测等级与实际等级之间的偏差
   2. 均方根误差(RMSE)与MAE相似，但更着重于较大的偏差

$$
\begin{array}{l}
   MAE = \frac{1}{n}\sum\limits_{i=1}\limits^n|p_i - r_i| \\
   \ \\
   RASE = \sqrt{\frac{1}{n}\sum\limits_{i=1}\limits^n(p_i - r_i)^2}
\end{array}
$$

## 8.11. 建立基本事实的困境
- IR度量经常被使用

| 离线实验                                                                   | 在线实验                               |
| -------------------------------------------------------------------------- | -------------------------------------- |
| 评级，交易                                                                 | 评分，反馈                             |
| 历史数据，并非所有的推荐物品都是被评级的                                   | 在线数据，所有的推荐物品都是被评级了的 |
| 未评级的商品的未知，但是会被解释为坏的(默认假设是用户只会购买评分高的商品) | 未推荐的物品的好坏是未知的             |
| 如果默认假设不成立，真正性可能很小，真负性可能很小                         | 假负性和真负性不能被确定               |
| 准确率偏高，召回率可能有多种情况                                           | 准确率尚可，召回率存疑                 |

> 结果表明，对在线用户的行为缺乏准确性。

## 8.12. 离线实验
1. Netflix竞争
   1. 基于网络的电影租赁
   2. 和目前已有的电影
2. 历史数据集
   1. 约480K用户
   2. 约18K影片，被在1-5之间评分
   3. 约100M的评分
   4. 最后9个评分/未显示用户
      1. 训练集(概率集)-用于评估的团队
      2. 测验集-评估团队提交的排行榜
      3. 测试集-Netflix用于确定获胜者

### 8.12.1. 方法论
1. **设置以确保内部有效性**：
   1. 随机选择一部分已知等级(训练集)作为输入来训练算法和建立模型
   2. 通过模型，系统可以在运行时计算建议。
   3. 评估模型质量所需的保留评级(测试集)的剩余份额
   4. 为了确保测量的可靠性，随机拆分，模型建立和评估步骤重复了几次
2. **N折交叉验证是分层随机选择程序**
   1. 确定大小相等($\frac{1}{5}$)的N个已知等级的分离分数
   2. N次重复的模型构建和评估步骤，其中每个分数仅一次用作测试集，而其他分数则用于训练
   3. 将N设置为5或10很受欢迎

### 8.12.2. 结果分析
1. 观察到的差异在统计上有意义还是由于偶然？
   1. 测试两个偏离度量标准的统计显着性的标准程序是方差成对分析(ANOVA)
   2. 零假设H0：观察到的差异是由于偶然
   3. 如果测试统计结果拒绝H0，则可以报告发现的重要性
2. 差异的实际重要性？
   1. 影响的大小及其实际影响
   2. 所观察到的影响的外部有效性或普遍性

## 8.13. 在线实验
1. 不同算法推荐手机游戏的效果
2. 在商业移动互联网门户网站上吸引了15万用户
3. 推荐方法比较
4. 随机分配用户给具体方法...

## 8.14. 实验设计
1. 在评估期间，从访问者那里提取了代表性的样本155,000个客户
   1. 这些被分为6组，大约有22,300个客户
   2. 注意确保客户档案中包含所有变体的足够信息(评级)以提出建议
   3. 选择组来代表相似的客户群
2. 提供了1,000种游戏的目录
3. 使用范围从-2到+2的五点评分量表对项目进行评分：由于明确等级的数量少，因此将游戏的"详细信息"链接单击为隐式" 0"等级，将购买解释为" 1"等级
4. 个性化推荐与非个性化推荐技术的假设及其在
   1. 提高转化率(即成为购买者的用户份额)
   2. 刺激额外购买(即增加平均购物篮大小)

## 8.15. 无实验研究
1. 准实验：缺乏随机分配给不同的单位
2. 非实验/观察研究
   1. 调查/问卷
   2. 纵向研究
      1. 长时间观察
      2. 例如 客户终生价值，回头客
   3. 实例探究
      1. 专注于回答有关如何以及为什么的研究问题
      2. 例如 回答类似的问题：如何推荐技术为Amazon.com做出了贡献，成为了全球最大的图书零售商？
   4. 焦点小组
      1. 面试
      2. 考虑aloud协议

### 8.15.1. 准实验
1. Ski- Europe.com推出的SkiMatcher Resort Finder，可根据用户的喜好向用户提供建议
2. 会话型RS
   1. 问答对话框
   2. 用户偏好与知识库的匹配
3. 2001年，德尔加多和戴维森(Delgado and Davidson)在4个月的时间内评估了推荐人的有效性：被归类为准实验，因为用户自行决定是否要使用推荐器

![](img/lec8/65.png)

### 8.15.2. 解释结果
1. 此研究设计的性质意味着无法回答因果关系问题(缺少随机分配)，例如
   1. 推荐系统的用户更有可能转化吗？
   2. 推荐系统本身是否会引起用户转换？ 一些隐藏的外生变量可能会影响使用RS的选择以及转换。
2. 但是，在使用推荐系统和提出建议之间存在重大关联
3. 影响范围已在其他领域复制
   1. 旅游
   2. 电子消费产品

### 8.15.3. 什么是受欢迎的
1. 对历史数据集测量准确性的评估
2. 最受欢迎的数据集
   1. 电影(MovieLens，EveryMovie，Netflix)
   2. Web 2.0平台(标签，音乐，论文等)
3. 最受欢迎的准确性度量
   1. 精度/召回率:项目分为好或坏
   2. MAE(平均绝对误差)，RMSE(均方根误差):物品按给定的等级进行评分
4. 数据的可用性严重影响了所做的工作
   1. 在RecSys会议上进行男高音，以促进现场实验
   2. 支持A / B测试的公共基础架构
5. 文献中的定量调查
   1. 有关IS和IR的高级期刊
   2. 信息系统ACM交易
6. 评估设计ACM TOIS 2004-2010
   1. 总共有15条关于RS的文章
   2. 近50％的电影领域
   3. 80％的离线实验
   4. 在实验室条件下的2个用户实验
   5. 1个定性研究

# 9. 讨论和总结
1. 介绍了经验研究的一般原理以及评价推荐技术的实践现状
2. 专注于如何对历史数据集进行经验评估
3. 讨论用于衡量建议准确性或覆盖范围的不同方法和度量标准。
4. 在实践中通常会使用哪些研究设计的概述。
5. 从技术角度来看，测量预测的准确性是公认的评估目标:但是其他可能会严重影响推荐系统总体效果的其他方面在很大程度上尚不完善

# 10. 重要并且实际的建议

## 10.1. 评估
| ![](img/lec8/15.png) | ![](img/lec8/16.png) |
| -------------------- | -------------------- |

- 将预测与已知评级进行比较
  - 均方根误差(RMSE):$\sqrt{\sum\limits_{xi}(r_{xi} - r_{xi}^*)^2}$，其中$r_{xi}$为预测值，$r_{xi}^* $是x在i上的真实评级
  - 预测前10位
  - 排序相关性：Spearman相关性在系统和用户完整排名之间
- 另一种方法:0/1模型
  - 承保范围：系统可以预测的项目/用户数
  - 精度：预测的准确性
  - 接收器工作特性(ROC)：误报与误报之间的折衷曲线

## 10.2. 错误矩阵
1. 仅仅关注准确率有时候会丢失重点
   1. 预测多样性
   2. 预测上下文
   3. 预测顺序
2. RMSE可能会惩罚一种对高评级有效而对其他不利的方法

## 10.3. 复杂度和速度
- 昂贵的步骤是找到k个最相似的客户：$O(|X|)$
- 在运行时执行成本太高：可以预先计算
- 朴素的预计算需要时间$O(k * |X|)$：X:客户群
- 我们已经知道该怎么做！
  - 高维(LSH)的近邻搜索
  - 聚类
  - 降维

## 10.4. 添加数据
1. 利用所有数据
   1. 请勿尝试减少数据大小以使精美算法发挥作用
   2. 处理大数据的简单方法最有效
2. 添加更多数据例如，在流派上添加IMDB数据

# 11. Netflix比赛(没讲)
1. 训练集:
   1. 1亿评分，480,000用户，17,770电影
   2. 使用了六年的数据:2000-2005
2. 测试集
   1. 最后2,800,000用户的评分信息
   2. 评估效果:RMSE(Root Mean Square Error):$=\frac{1}{|R|}\sqrt{\sum\limits_{(i, x)\in R}(\hat{r_{xi}} - r_{xi})^2}$
   3. Netflix系统RMSE:0.9514
3. 比赛:
   1. 2,700+团队
   2. 1,000,000奖励给为Netfix达到10%提升的团队

| ![](img/lec8/17.png) | ![](img/lec8/18.png) |
| -------------------- | -------------------- |

## 11.1. BellKor 推荐系统
1. Netfix挑战的获胜者
2. 数据的多尺度建模：将数据的顶级"区域"建模与精致的本地视图结合起来：
   1. 全球：用户/电影的总体偏差
   2. 因式分解：解决"区域性"影响
   3. 协同过滤：提取局部模式

![](img/lec8/19.png)

### 11.1.1. 局部建模和全局提升
1. 全局上
   1. 平均影片评分为3.7星
   2. 电影第六感比平均分要高0.5星
   3. Joe打分比平均分低0.2星
   4. 可以推断出来:Joe给电影第六感打分4星
2. 局部邻居(CF/NN):Joe不喜欢相关的电影Signs，最终推断 出来Joe会给电影第六感打分3.8分

### 11.1.2. CF:协同过滤
- 最早和最受欢迎的协作过滤方法
- 从"相似"电影(项目-项目变体)中获得未知的评级
- 定义项目i和j的相似性度量$s_{ij}$
- 选择k个最近的邻居，计算等级：$N(i; x)$：与x评级最相似的项

$$
\hat{r_{xi}} = \frac{\sum\limits_{j \in N(i; x)}s_{ij} * r_{xj}}{\sum\limits_{j \in N(i; x)} s_{ij}}
$$

1. $s_{ij}$:项目i和j的相似性
2. $r_{xj}$:用户x对项目j的评级
3. $N(i; x)$:与x评分的与项目i相似的项目集
4. 实际上，如果我们能得到更好的估计
模型偏差：

$$
\begin{array}{l}
   \hat{r_{xi}} = b_{xi} + \frac{\sum\limits_{j \in N(i; x)} s_{ij} * (r_{xj} - b_{xj})}{\sum\limits_{j \in N(i; x)}s_{ij}} \\
   b_{xi} = \mu + b_x + b_i \\
\end{array}
$$

- 问题/问题：
  - 相似性度量是"任意的"
  - 成对相似性忽略了用户之间的相互依赖性
  - 取加权平均值可能是限制
- 解决方案：代替$s_{ij}$，使用我们直接根据数据估算的$w_{ij}$

### 11.1.3. 想法:使用权重$w_{ij}$来修正
1. 使用权重和而不是权重均值

$$
\hat{r_{xi}} = b_{xi} + \sum\limits_{j \in N(i;x)} w_{ij}(r_{xj} - b{xj})
$$

2. 注意点
   1. $N(i; x)$：用户x评分与电影i类似的电影的集合
   2. $w_{ij}$是插值权重(一些实数)，我们允许$\sum\limits_{j \in N(i;x)} w_{ij} \neq 1$
   3. $w_{ij}$模拟电影对之间的对应(不取决于用户x)
3. 如何设置$w_{ij}$
4. 误差矩阵:
   1. $\frac{1}{|R|}\sqrt{\sum\limits_{(i, x)\in R}(\hat{r_{xi}} - r_{xi})^2}$
   2. 或者等效SSE：$\sum\limits_{(i, x)\in R}(\hat{r_{xi}} - r_{xi})^2$
5. 找到$w_{ij}$在训练集上最小化SSE
6. $w_{ij}$可以根据x和其他所有对i进行评级的用户来学习/估算

## 11.2. 优化推荐问题
1. 目标:完成好的推荐
   1. 使用RMSE量化优势：
   2. 降低RMSE => 更好的建议
2. 希望对用户尚未看到的项目提出好的建议。实际做不到！
3. 假设建立一个可以在已知(用户，物品)评分上正常运行的系统，并希望该系统也能很好地预测未知评分
4. 想法：让我们设置值w，使其在已知(用户，商品)评分上正常运行
5. 如何找到这样的值w？
6. 想法：定义目标函数并解决优化问题
7. 找到可将训练数据上的SSE降至最低的$w_{ij}$！

$J(W) = \sum\limits_{x, i}([b_{xi} + \sum\limits_{j \in N(i; x)} w_{ij}(r_{xj} - b_{xj})]-r_{xi})^2$

## 11.3. 差值权重
1. 我们有一个优化问题，如何解决呢？梯度下降法
   1. 迭代直到收敛:$w\leftarrow w - \eta \triangledown_w j$
   2. 收敛是指:$|w_{new} = w_{old}| \leq \epsilon$
   1. $\triangledown_w j$是梯度

$$
\begin{array}{l}
   \triangledown_w j = [\frac{\delta J(w)}{\delta w_{ij}}] = 2\sum\limits_{x, i}([b_{xi} + \sum\limits_{j \in N(i; x)} w_{ij}(r_{xj} - b_{xj})]-r_{xi})(r_{xi} - b_{xj}) \\
   for\ j \in \{N(i;x),\forall i, \forall x\} \\
   else\ \frac{\delta J(w)}{\delta w_{ij}} = 0 \\
\end{array}
$$

- 我们为每一个电影i，计算到$r_{xi}$,对于每一个电影$j \in N(i;x)$，我们计算梯度

- 到目前为止，$\widehat{r_{xi}} = b_{xi} + \sum\limits_{j \in N(i;x)} w_{ij}(r_{xj} - b_{xj})$\
  - 权重$w_{ij}$是来自其作用的，不使用任意相似性度量($w_{ij} \neq s_{ij}$)
  - 明确说明相邻电影之间的相互关系
- 之后：明确考虑潜在因子模型之间的相互关系，提取邻近电影的"区域"相关性

![](img/lec8/23.png)

# 12. 不同方法的表现
![](img/lec8/24.png)

# 13. 潜在因素模型(比如SVD)
![](img/lec8/25.png)

- "SVD" on Netflix data: $R \approxeq Q*P^T$

![](img/lec8/26.png)

- 现在，假设我们可以将评分矩阵R近似为"薄" $Q*P^T$的乘积:R缺少条目，但现在暂时忽略吧！基本上，我们希望重建误差在已知等级上要小一些，而我们不在乎缺失值上的值

## 13.1. 找到潜在因素

### 13.1.1. 潜在因素模型
1. 我们的布标是找到P和Q满足:$\min\limits_{P, Q}\sum_{(i, x) \in R}(r_{xi} - q_i * p_x)^2$

![](img/lec8/27.png)

### 13.1.2. 回到最初的问题
1. 目标:我们想要在位置的测试集上最小化SSE
2. 想法：最小化培训数据上的SSE
   1. 想要大k(因子数)来捕获所有信号
   2. 但是，当k> 2时，测试数据的SSE开始上升
3. 这是过度拟合的经典示例：
   1. 自由度太大(自由参数太多)，模型开始拟合噪声：这太适合培训数据，因此不能很好地推广到看不见的测试数据

### 13.1.3. 处理缺失值
1. 为了解决过度拟合问题，我们引入了正则化：
   1. 在有足够数据的情况下允许丰富模型
   2. 在缺乏数据的地方大幅度缩水

$$
\min\limits_{P, Q} \sum\limits_{training}(r_{xi} - q_ip_x)^2 + [\lambda_1\sum_{x}||p_x||^2 +\lambda_2\sum\limits_{i}||q_i||^2]
$$

2. $\lambda_1,\lambda_2$是用户设置的正则化参数
3. 我们不在乎目标函数的"原始"值，但我们关注的是达到目标最小值的P，Q

### 13.1.4. 正则化的作用
| ![](img/lec8/28.png) | ![](img/lec8/29.png) |
| -------------------- | -------------------- |
| ![](img/lec8/30.png) | ![](img/lec8/31.png) |

### 13.1.5. 随机梯度下降
1. 我们想要找到这样子的矩阵P和Q满足:

$$
\min\limits_{P,Q}\sum\limits_{traing}(r_{xi} - q_{i}p_{x})^2 + [\lambda_{1}\sum\limits_{x}||p_x||^2 + \lambda_2\sum\limits_{i}||q_i||^2]
$$

2. 梯度下降算法
   1. 初始化矩阵P和Q(使用SVD，假设缺失的评分是0)
   2. 进行梯度下降
      1. $P \leftarrow P - \eta \triangledown P$
      2. $Q \leftarrow Q - \eta \triangledown Q$
      3. $\triangledown Q$是矩阵Q的梯度/倒数
         1. $\triangledown D = [\triangledown q_{if}]$ 并且 $q_{if}=\sum_{x, i} - 2(r_{xi} - q_ip_x)p_{xf} + 2\lambda_2q_{if}$
         2. $q_{if}$是矩阵Q的qi行的条目f
   3. 我们可以发现计算梯度是慢的
3. 梯度下降与随机梯度下降
   1. 观察到:$\triangledown Q = [\triangledown q_{if}] where \triangledown q_{if} = \sum\limits_{x, i} - 2(r_{xi} - q_{if}p_{xf}p_{xf} + 2\lambda q_{if} = \sum\limits_{x,i}\triangledown Q(r_{xi})$，$q_{if}$是矩阵Q的qi行的条目f
   3. $Q = Q - \eta \triangledown Q = Q - \eta[\sum\limits_{x,i} \triangledown Q(x_{xi})]$
   4. 而不是评估所有等级的梯度，而是针对每个单独的等级对其进行评估，并迈出一步
4. GD:$Q = Q - \eta[\sum\limits_{x,i} \triangledown Q(x_{xi})]$
5. SGD:$Q = Q - \mu\triangledown Q(r_{xi})$，收敛更快！需要更多步骤，但每个步骤的计算速度都更快
6. GD在每一步都提高了目标函数的值。 SGD以"嘈杂"的方式提高了价值。GD收敛所需的步骤更少，但计算所需的时间更长。 实际上，SGD快得多！

![](img/lec8/32.png)

- 随机梯度下降法步骤:
  - 使用SVD，假设缺失值为空，初始化P和Q
  - 然后遍历等级(如有必要，多次)并更新系数：
  - 对于每一个$r_{xi}$
    - 计算代价：$\epsilon_{xi} = 2(r_{xi} - q_i * p_x)$
    - 更新：$q_i \leftarrow q_i + \mu_1(\epsilon_{xi} p_x - \lambda_2 q_i$
    - 更新：$p_x \leftarrow p_x + \mu_2(\epsilon_{xi} q_i - \lambda_1 p_x$
    - $\mu$为学习率
  - 对于每一个$r_{xi}$执行，直到收敛

## 13.2. 扩展潜在因子模型以包括偏差

### 13.2.1. 建模偏差和相互作用
![](img/lec8/33.png)

- $\mu$:整体平均打分
- $b_x$:用户x的偏差
- $b_i$:电影i的偏差

### 13.2.2. 基线预测器
- 基线预测我们期望用户x对电影i的评分，即使没有估计x对ior等电影的态度

![](img/lec8/34.png)

### 13.2.3. 将所有的数据放在一起
$r_{xi} = \mu(Overall\ mean\ rating) + b_x(Bias\ for\ user\ x$ + $b_i(Bias\ for\ movie\ i) + q_i * p_x(User-Movie\ Interaction)$

- 例：
  - 平均评级：μ= 3.7
  - 您是一位重要的评论者：您的评分比平均值低1星：bx = -1
  - 《星球大战》的平均评级比普通电影高0.5：bi = + 0.5
  - 对《星球大战》的预测评分：= 3.7-1 + 0.5 = 3.2

### 13.2.4. 适配新模型
1. 解决问题:

$$
\min_{Q,P}\sum_{(x, i)\in R}(r_{xi}  - (\mu + b_x + b_i + q_i * p_x))^2 + (\lambda_1\sum\limits_{i}||q_i||^2 + \lambda_2\sum\limits_{x}||p_x||^2 + \lambda_3\sum\limits_x||b_x||^2 + \lambda_4\sum\limits_i||b_i||^2)
$$

- 随机梯度下降以查找参数
- 注意：两个偏差$b_x$，$b_i$以及相互作用$q_i$，$p_x$均被视为参数(我们对其进行估算)

## 13.3. 不同方法的性能比较
| ![](img/lec8/35.png) | ![](img/lec8/36.png) |
| -------------------- | -------------------- |

# 14. The Netflix Chanllenge:2006-09

## 14.1. 用户的时间偏向
- 电影平均收视率突然上升(2004年初)
  - Netflix的改进
  - GUI改进
  - 评级的含义已更改
- 电影时代
  - 用户无缘无故喜欢新电影
  - 老电影天生就比新电影好

![](img/lec8/37.png)

## 14.2. 用户时间偏向和影响
1. 最初的模型:$r_{xi} = \mu + b_x + b_i + q_i*p_x$
2. 为模型添加时间依赖:$r_{xi} = \mu + b_x(t) + b_i(t) + q_i*p_x$
   1. 使得参数$b_x, b_i$依赖于时间
   2. 通过线性趋势参数化时间依赖性
   3. 每个Bin对应连续10周(b_i(t) = b_i + b_{i, Bin(t)})
3. 添加时间以来到因素上去:$p_x(t)$用户根据时间t相关的喜欢变量

| ![](img/lec8/38.png) | ![](img/lec8/39.png) |
| -------------------- | -------------------- |
| ![](img/lec8/40.png) |                      |

## 14.3. 最新30天
- Ensemble团队成立
  - 排行榜上的其他团队组成一个新团队
  - 依靠结合他们的模型
  - 快速获得合格分数超过10％
- 贝尔(BellKor)
  - 继续在分数上取得小进步
  - 意识到他们与Ensemble有直接竞争关系
- 策略
  - 两支球队都认真监控排行榜
  - 唯一确定改进的方法是提交一组预测
  - 这会提醒另一支球队您的最新分数

## 14.4. DDL前24个小时
- 每天最多提交1次：在过去24小时内只能提交1份最终作品
- 在截止日期前24小时：奥地利BellKor小组成员注意到(偶然)，Ensemble的得分略高于BellKor的得分
- 两支球队最后24小时疯狂
  - 最终优化需要大量的计算机时间
  - 经过仔细校准，在截止日期前约一个小时结束
- 最终提交
  - BellKor故意提前40分钟提交
  - The Ensemble在20分钟后提交最终作品,每个人都在等待