
<!DOCTYPE HTML>
<html lang="" >
    <head>
        <meta charset="UTF-8">
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <title>Tec6-文本预处理与关键词提取 · GitBook</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="GitBook 3.2.3">
        
        
        
    
    <link rel="stylesheet" href="gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-highlight/website.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-search/search.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-fontsettings/website.css">
                
            
        

    

    
        
    
        
    
        
    
        
    
        
    
        
    

        
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="gitbook/images/favicon.ico" type="image/x-icon">

    
    <link rel="next" href="Tec7-图片处理.html" />
    
    
    <link rel="prev" href="Tec5-pdfminer.html" />
    

    </head>
    <body>
        
<div class="book">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="Type to search" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    

    

    
        
        
    
        <li class="chapter " data-level="1.1" data-path="./">
            
                <a href="./">
            
                    
                    Introduction
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2" data-path="Exam-整理.html">
            
                <a href="Exam-整理.html">
            
                    
                    Exam-整理
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3" data-path="Lecture1-大数据分析.html">
            
                <a href="Lecture1-大数据分析.html">
            
                    
                    Lecture1-大数据分析
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4" data-path="Lecture2-大数据平台.html">
            
                <a href="Lecture2-大数据平台.html">
            
                    
                    Lecture2-大数据平台
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5" data-path="Lecture3-大数据存储和处理.html">
            
                <a href="Lecture3-大数据存储和处理.html">
            
                    
                    Lecture3-大数据存储和处理
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6" data-path="Lecture4-链接分析.html">
            
                <a href="Lecture4-链接分析.html">
            
                    
                    Lecture4-链接分析
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7" data-path="Lecture5-数据降维.html">
            
                <a href="Lecture5-数据降维.html">
            
                    
                    Lecture5-数据降维
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.8" data-path="Lecture6-分类.html">
            
                <a href="Lecture6-分类.html">
            
                    
                    Lecture6-分类
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.9" data-path="Lecture7-聚类.html">
            
                <a href="Lecture7-聚类.html">
            
                    
                    Lecture7-聚类
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.10" data-path="Lecture8-推荐系统.html">
            
                <a href="Lecture8-推荐系统.html">
            
                    
                    Lecture8-推荐系统
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.11" data-path="Lecture9-知识图谱.html">
            
                <a href="Lecture9-知识图谱.html">
            
                    
                    Lecture9-知识图谱
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.12" data-path="Lecture10-Graph%20DB.md">
            
                <span>
            
                    
                    Lecture10-Graph%20DB
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.13" data-path="Lecture11-图挖掘.html">
            
                <a href="Lecture11-图挖掘.html">
            
                    
                    Lecture11-图挖掘
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.14" data-path="Lecture12-Spark与数据分析.html">
            
                <a href="Lecture12-Spark与数据分析.html">
            
                    
                    Lecture12-Spark与数据分析
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.15" data-path="Tec1-TF-IDF算法.html">
            
                <a href="Tec1-TF-IDF算法.html">
            
                    
                    Tec1-TF-IDF算法
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.16" data-path="Tec2-安装Hadoop和Spark.html">
            
                <a href="Tec2-安装Hadoop和Spark.html">
            
                    
                    Tec2-安装Hadoop和Spark
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.17" data-path="Tec3-yolo.html">
            
                <a href="Tec3-yolo.html">
            
                    
                    Tec3-yolo
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.18" data-path="Tec4-情感分析.html">
            
                <a href="Tec4-情感分析.html">
            
                    
                    Tec4-情感分析
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.19" data-path="Tec5-pdfminer.html">
            
                <a href="Tec5-pdfminer.html">
            
                    
                    Tec5-pdfminer
            
                </a>
            

            
        </li>
    
        <li class="chapter active" data-level="1.20" data-path="Tec6-文本预处理与关键词提取.html">
            
                <a href="Tec6-文本预处理与关键词提取.html">
            
                    
                    Tec6-文本预处理与关键词提取
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.21" data-path="Tec7-图片处理.html">
            
                <a href="Tec7-图片处理.html">
            
                    
                    Tec7-图片处理
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.22" data-path="Tec8-鸢尾花数据集分类.html">
            
                <a href="Tec8-鸢尾花数据集分类.html">
            
                    
                    Tec8-鸢尾花数据集分类
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.23" data-path="Tec9-SVD.html">
            
                <a href="Tec9-SVD.html">
            
                    
                    Tec9-SVD
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.24" data-path="Tec10-基于MovieLens的推荐系统.html">
            
                <a href="Tec10-基于MovieLens的推荐系统.html">
            
                    
                    Tec10-基于MovieLens的推荐系统
            
                </a>
            

            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
            Published with GitBook
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href="." >Tec6-文本预处理与关键词提取</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <h2 id="tec6-&#x6587;&#x672C;&#x9884;&#x5904;&#x7406;&#x548C;&#x5173;&#x952E;&#x8BCD;&#x5904;&#x7406;">Tec6-&#x6587;&#x672C;&#x9884;&#x5904;&#x7406;&#x548C;&#x5173;&#x952E;&#x8BCD;&#x5904;&#x7406;</h2>
<ul>
<li>&#x672C;&#x6587;&#x662F;&#x82F1;&#x6587;&#x5904;&#x7406;</li>
<li>&#x5168;&#x90E8;&#x4EE3;&#x7801;&#x9644;&#x5728;&#x6587;&#x672B;</li>
</ul>
<h1 id="1-&#x6587;&#x672C;&#x9884;&#x5904;&#x7406;">1. &#x6587;&#x672C;&#x9884;&#x5904;&#x7406;</h1>
<h2 id="11-&#x6587;&#x672C;&#x5185;&#x5BB9;&#x5904;&#x7406;">1.1. &#x6587;&#x672C;&#x5185;&#x5BB9;&#x5904;&#x7406;</h2>
<ol>
<li>&#x9996;&#x5148;&#x53BB;&#x9664;&#x5927;&#x5C0F;&#x5199;:<code>line = line.lower()</code></li>
<li>&#x7136;&#x540E;&#x53BB;&#x9664;&#x7279;&#x6B8A;&#x5B57;&#x7B26;:<code>line = re.sub(&apos;[\W_]+&apos;, &quot; &quot;, line)</code></li>
<li>&#x4E4B;&#x540E;&#x53BB;&#x9664;&#x5BF9;&#x672C;&#x5B9E;&#x9A8C;&#x6CA1;&#x6709;&#x610F;&#x4E49;&#x7684;&#x6570;&#x5B57;:<code>line = re.sub(&apos;[0-9]&apos;, &quot; &quot;, line)</code></li>
<li>&#x6392;&#x9664;&#x6389;&#x4E2D;&#x6587;&#x5B57;&#x7B26;:<code>line = re.sub(r&apos;[\u4e00-\u9fa5]&apos;, &quot;&quot;, line)</code></li>
</ol>
<h2 id="12-&#x6587;&#x672C;&#x5206;&#x8BCD;">1.2. &#x6587;&#x672C;&#x5206;&#x8BCD;</h2>
<ol>
<li>&#x6587;&#x672C;&#x5206;&#x8BCD;&#x7684;&#x5BFC;&#x5165;:<code>from nltk import word_tokenize</code></li>
<li>&#x6587;&#x672C;&#x5206;&#x8BCD;&#x7684;&#x5904;&#x7406;:<code>words = word_tokenize(line)</code></li>
</ol>
<h2 id="13-&#x505C;&#x7528;&#x8BCD;&#x5904;&#x7406;">1.3. &#x505C;&#x7528;&#x8BCD;&#x5904;&#x7406;</h2>
<ol>
<li>&#x52A0;&#x8F7D;&#x505C;&#x7528;&#x8BCD;&#x8868;&#x5E76;&#x4E14;&#x5B8C;&#x6210;&#x5BF9;&#x5206;&#x8BCD;&#x540E;&#x7684;&#x6587;&#x672C;&#x8FDB;&#x884C;&#x5904;&#x7406;</li>
</ol>
<pre><code class="lang-py">temp_words = word_tokenize(line)
<span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> temp_words:
    <span class="hljs-keyword">if</span> word <span class="hljs-keyword">in</span> stopwords:
        <span class="hljs-keyword">continue</span>
    words.append(word)
</code></pre>
<h2 id="14-&#x8BCD;&#x5E72;&#x63D0;&#x53D6;">1.4. &#x8BCD;&#x5E72;&#x63D0;&#x53D6;</h2>
<h2 id="15-&#x8BCD;&#x5F62;&#x8FD8;&#x539F;">1.5. &#x8BCD;&#x5F62;&#x8FD8;&#x539F;</h2>
<ol>
<li>&#x8BCD;&#x5F62;&#x8FD8;&#x539F;&#x662F;&#x6587;&#x672C;&#x9884;&#x5904;&#x7406;&#x4E2D;&#x5F88;&#x91CD;&#x8981;&#x90E8;&#x5206;</li>
<li>&#x8BCD;&#x5F62;&#x8FD8;&#x539F;&#x5C31;&#x662F;&#x53BB;&#x6389;&#x5355;&#x8BCD;&#x7684;&#x8BCD;&#x7F00;&#xFF0C;&#x63D0;&#x53D6;&#x5355;&#x8BCD;&#x7684;&#x4E3B;&#x5E72;&#x90E8;&#x5206;&#xFF0C;&#x901A;&#x5E38;&#x63D0;&#x53D6;&#x540E;&#x7684;&#x5355;&#x8BCD;&#x4F1A;&#x662F;&#x5B57;&#x5178;&#x4E2D;&#x7684;&#x5355;&#x8BCD;&#x3002;</li>
<li>&#x548C;&#x8BCD;&#x5E72;&#x63D0;&#x53D6;&#x7684;&#x4E0D;&#x540C;&#xFF1A;&#x63D0;&#x53D6;&#x540E;&#x7684;&#x5355;&#x8BCD;&#x4E0D;&#x4E00;&#x5B9A;&#x4F1A;&#x51FA;&#x73B0;&#x5728;&#x5355;&#x8BCD;&#x4E2D;</li>
<li>&#x672C;&#x6587;&#x9009;&#x7528;&#x4E86;nltk&#x4E2D;&#x5305;&#x542B;&#x7684;WordNet&#x6240;&#x63D0;&#x4F9B;&#x7684;&#x7A33;&#x5065;&#x7684;&#x8BCD;&#x5F62;&#x8FD8;&#x539F;&#x7684;&#x51FD;&#x6570;&#x3002;</li>
</ol>
<h3 id="151-&#x6839;&#x636E;&#x8BCD;&#x5F62;&#x83B7;&#x53D6;&#x539F;&#x5355;&#x8BCD;">1.5.1. &#x6839;&#x636E;&#x8BCD;&#x5F62;&#x83B7;&#x53D6;&#x539F;&#x5355;&#x8BCD;</h3>
<pre><code class="lang-py"><span class="hljs-keyword">from</span> nltk.stem <span class="hljs-keyword">import</span> WordNetLemmatizer

wnl = WordNetLemmatizer()
<span class="hljs-comment"># lemmatize nouns</span>
print(wnl.lemmatize(<span class="hljs-string">&apos;cars&apos;</span>, <span class="hljs-string">&apos;n&apos;</span>)) <span class="hljs-comment"># cars</span>
print(wnl.lemmatize(<span class="hljs-string">&apos;men&apos;</span>, <span class="hljs-string">&apos;n&apos;</span>)) <span class="hljs-comment"># man</span>

<span class="hljs-comment"># lemmatize verbs</span>
print(wnl.lemmatize(<span class="hljs-string">&apos;running&apos;</span>, <span class="hljs-string">&apos;v&apos;</span>)) <span class="hljs-comment"># run</span>
print(wnl.lemmatize(<span class="hljs-string">&apos;ate&apos;</span>, <span class="hljs-string">&apos;v&apos;</span>)) <span class="hljs-comment"># eat</span>

<span class="hljs-comment"># lemmatize adjectives</span>
print(wnl.lemmatize(<span class="hljs-string">&apos;saddest&apos;</span>, <span class="hljs-string">&apos;a&apos;</span>)) <span class="hljs-comment">#sad</span>
print(wnl.lemmatize(<span class="hljs-string">&apos;fancier&apos;</span>, <span class="hljs-string">&apos;a&apos;</span>)) <span class="hljs-comment"># fancy</span>
</code></pre>
<ul>
<li><code>lemmatize</code>&#x9700;&#x8981;&#x4E24;&#x4E2A;&#x53C2;&#x6570;&#xFF0C;&#x7B2C;&#x4E00;&#x4E2A;&#x53C2;&#x6570;&#x662F;&#x5355;&#x8BCD;&#xFF0C;&#x7B2C;&#x4E8C;&#x4E2A;&#x53C2;&#x6570;&#x662F;&#x672C;&#x5355;&#x8BCD;&#x7684;&#x8BCD;&#x5F62;&#xFF0C;&#x8FD4;&#x56DE;&#x7ED3;&#x679C;&#x4E3A;&#x8BCD;&#x5F62;&#x8FD8;&#x539F;&#x540E;&#x7684;&#x7ED3;&#x679C;</li>
<li>&#x95EE;&#x9898;:&#x6307;&#x5B9A;&#x5355;&#x8BCD;&#x7684;&#x8BCD;&#x5F62;&#x5F88;&#x91CD;&#x8981;&#xFF0C;&#x4E0D;&#x7136;&#x8BCD;&#x5F62;&#x8FD8;&#x539F;&#x7ED3;&#x679C;&#x4E0D;&#x597D;&#x3002;</li>
</ul>
<h3 id="152-&#x83B7;&#x53D6;&#x5355;&#x8BCD;&#x7684;&#x8BCD;&#x5F62;">1.5.2. &#x83B7;&#x53D6;&#x5355;&#x8BCD;&#x7684;&#x8BCD;&#x5F62;</h3>
<ul>
<li>&#x5728;NLP&#x4E2D;&#xFF0C;&#x4F7F;&#x7528;Parts of Speech(POS)&#x6280;&#x672F;&#x5B9E;&#x73B0;&#x3002;&#x5728;nltk&#x4E2D;&#xFF0C;&#x53EF;&#x4EE5;&#x4F7F;&#x7528;nltk.pos_tags()&#x83B7;&#x53D6;&#x5355;&#x8BCD;&#x5728;&#x53E5;&#x5B50;&#x4E2D;&#x7684;&#x8BCD;&#x5F62;</li>
</ul>
<pre><code class="lang-py">sentence = <span class="hljs-string">&apos;The brown fox is quick and he is jumping over the lazy dog&apos;</span>
<span class="hljs-keyword">import</span> nltk
tokens = nltk.word_tokenize(sentence)
tagged_sent = nltk.pos_tag(tokens)
print(tagged_sent)
<span class="hljs-comment"># [(&apos;The&apos;, &apos;DT&apos;), (&apos;brown&apos;, &apos;JJ&apos;), (&apos;fox&apos;, &apos;NN&apos;), (&apos;is&apos;, &apos;VBZ&apos;), (&apos;quick&apos;, &apos;JJ&apos;), (&apos;and&apos;, &apos;CC&apos;), (&apos;he&apos;, &apos;PRP&apos;), (&apos;is&apos;, &apos;VBZ&apos;), (&apos;jumping&apos;, &apos;VBG&apos;), (&apos;over&apos;, &apos;IN&apos;), (&apos;the&apos;, &apos;DT&apos;), (&apos;lazy&apos;, &apos;JJ&apos;), (&apos;dog&apos;, &apos;NN&apos;)]</span>
</code></pre>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td><img src="img/tec6/1.png" alt=""></td>
<td><img src="img/tec6/2.png" alt=""></td>
</tr>
</tbody>
</table>
<h1 id="2-nltkdata&#x4E0B;&#x8F7D;&#x5931;&#x8D25;">2. nltk_data&#x4E0B;&#x8F7D;&#x5931;&#x8D25;</h1>
<ul>
<li>&#x9519;&#x8BEF;&#x4EE3;&#x7801;
```
LookupError: </li>
</ul>
<hr>
<p>  Resource punkt not found.
  Please use the NLTK Downloader to obtain the resource:</p>
<blockquote>
<blockquote>
<blockquote>
<p>import nltk
nltk.download(&apos;punkt&apos;)</p>
</blockquote>
</blockquote>
</blockquote>
<p>  For more information see: <a href="https://www.nltk.org/data.html" target="_blank">https://www.nltk.org/data.html</a></p>
<p>  Attempted to load tokenizers/punkt/english.pickle</p>
<p>  Searched in:</p>
<pre><code>- &apos;C:\\Users\\user_name/nltk_data&apos;
- &apos;D:\\Anaconda\\nltk_data&apos;
- &apos;D:\\Anaconda\\share\\nltk_data&apos;
- &apos;D:\\Anaconda\\lib\\nltk_data&apos;
- &apos;C:\\Users\\user_name\\AppData\\Roaming\\nltk_data&apos;
- &apos;C:\\nltk_data&apos;
- &apos;D:\\nltk_data&apos;
- &apos;E:\\nltk_data&apos;
- &apos;&apos;
</code></pre><hr>
<pre><code>
&gt; &#x95EE;&#x9898;&#x5206;&#x6790;:`nltk.download()`&#x65E0;&#x6CD5;&#x4E0B;&#x8F7D;&#xFF0C;&#x9700;&#x8981;&#x81EA;&#x5DF1;&#x4E0B;&#x8F7D;&#x5B89;&#x88C5;

1. &lt;a href = &quot;http://www.nltk.org/nltk_data/&quot;&gt;nltk_data&#x7684;&#x4E0B;&#x8F7D;&#x94FE;&#x63A5;&lt;/a&gt;
2. &#x4E0B;&#x8F7D;&#x540E;&#x7684;&#x89E3;&#x538B;&#x7ED3;&#x679C;&#x653E;&#x7F6E;&#x5230;&#x4EE5;&#x4E0B;&#x4EFB;&#x610F;&#x6587;&#x4EF6;&#x4E2D;&#xFF0C;&#x6CE8;&#x610F;&#x89E3;&#x538B;&#x6587;&#x4EF6;&#x5939;&#x683C;&#x5F0F;
   1. `punkt`:`nltk_data/tokenizers/punkt`
   2. `taggers`:`nltk_data/averaged_perceptron_tagger`
   3. `wordnet`:`nltk_data/corpora/wordnet`
   4. `stopwords`:`nltk_data/corpora/stopwords`
</code></pre><ul>
<li>&apos;C:\Users\user_name/nltk_data&apos;</li>
<li>&apos;D:\Anaconda\nltk_data&apos;</li>
<li>&apos;D:\Anaconda\share\nltk_data&apos;</li>
<li>&apos;D:\Anaconda\lib\nltk_data&apos;</li>
<li>&apos;C:\Users\user_name\AppData\Roaming\nltk_data&apos;</li>
<li>&apos;C:\nltk_data&apos;</li>
<li>&apos;D:\nltk_data&apos;</li>
<li>&apos;E:\nltk_data&apos;
```</li>
</ul>
<h1 id="3-&#x6587;&#x672C;&#x5173;&#x952E;&#x63D0;&#x53D6;&#x4F7F;&#x7528;jieba">3. &#x6587;&#x672C;&#x5173;&#x952E;&#x63D0;&#x53D6;(&#x4F7F;&#x7528;jieba)</h1>
<h2 id="31-&#x4EC0;&#x4E48;&#x662F;jieba">3.1. &#x4EC0;&#x4E48;&#x662F;jieba</h2>
<ul>
<li>jieba&#x8F83;&#x591A;&#x7684;&#x5E94;&#x7528;&#x5728;&#x4E2D;&#x6587;&#x6587;&#x672C;&#x7684;&#x81EA;&#x7136;&#x8BED;&#x8A00;&#x5904;&#x7406;&#xFF0C;&#x6BD4;&#x8F83;&#x5E38;&#x7528;&#x5230;&#x7684;&#x662F;&#x5206;&#x8BCD;</li>
<li>jieba&#x5206;&#x8BCD;&#x6A21;&#x5F0F;:<ul>
<li>&#x7CBE;&#x786E;&#x6A21;&#x5F0F;&#xFF0C;&#x8BD5;&#x56FE;&#x5C06;&#x53E5;&#x5B50;&#x6700;&#x7CBE;&#x786E;&#x5730;&#x5207;&#x5F00;&#xFF0C;&#x9002;&#x5408;&#x6587;&#x672C;&#x5206;&#x6790;&#x3002;</li>
<li>&#x5168;&#x6A21;&#x5F0F;&#xFF0C;&#x53EF;&#x4EE5;&#x628A;&#x53E5;&#x5B50;&#x4E2D;&#x6240;&#x6709;&#x7684;&#x53EF;&#x4EE5;&#x5206;&#x8BCD;&#x7684;&#x8BCD;&#x8BED;&#x90FD;&#x626B;&#x63CF;&#x51FA;&#x6765;&#xFF0C;&#x901F;&#x5EA6;&#x975E;&#x5E38;&#x5FEB;&#xFF0C;&#x4F46;&#x662F;&#x4E0D;&#x80FD;&#x89E3;&#x51B3;&#x6B67;&#x4E49;&#x95EE;&#x9898;&#x3002;</li>
<li>&#x641C;&#x7D22;&#x5F15;&#x64CE;&#x6A21;&#x5F0F;&#xFF0C;&#x5728;&#x7CBE;&#x786E;&#x6A21;&#x5F0F;&#x7684;&#x57FA;&#x7840;&#x4E0A;&#xFF0C;&#x5BF9;&#x957F;&#x8BCD;&#x518D;&#x6B21;&#x5207;&#x5206;&#xFF0C;&#x63D0;&#x9AD8;&#x53EC;&#x56DE;&#x7387;&#xFF0C;&#x9002;&#x5408;&#x7528;&#x4E8E;&#x641C;&#x7D22;&#x5F15;&#x64CE;&#x5206;&#x8BCD;&#x3002;</li>
</ul>
</li>
<li>&#x652F;&#x6301;&#x7E41;&#x4F53;&#x5206;&#x8BCD;</li>
<li>&#x652F;&#x6301;&#x81EA;&#x5B9A;&#x4E49;&#x8BCD;&#x5178;</li>
<li>MIT&#x6388;&#x6743;&#x534F;&#x8BAE;</li>
</ul>
<h2 id="32-jieba&#x5206;&#x8BCD;&#x65B9;&#x6CD5;">3.2. jieba&#x5206;&#x8BCD;&#x65B9;&#x6CD5;</h2>
<table>
<thead>
<tr>
<th>&#x65B9;&#x6CD5;</th>
<th>&#x63CF;&#x8FF0;</th>
<th>&#x5907;&#x6CE8;</th>
</tr>
</thead>
<tbody>
<tr>
<td>cut</td>
<td>&#x65B9;&#x6CD5;&#x63A5;&#x53D7;&#x4E09;&#x4E2A;&#x8F93;&#x5165;&#x53C2;&#x6570;: &#x9700;&#x8981;&#x5206;&#x8BCD;&#x7684;&#x5B57;&#x7B26;&#x4E32;&#xFF1B;cut_all &#x53C2;&#x6570;&#x7528;&#x6765;&#x63A7;&#x5236;&#x662F;&#x5426;&#x91C7;&#x7528;&#x5168;&#x6A21;&#x5F0F;&#xFF1B;HMM &#x53C2;&#x6570;&#x7528;&#x6765;&#x63A7;&#x5236;&#x662F;&#x5426;&#x4F7F;&#x7528; HMM &#x6A21;&#x578B;</td>
<td>&#x8FD4;&#x56DE;&#x4E00;&#x4E2A;&#x53EF;&#x8FED;&#x4EE3;&#x7684;generator</td>
</tr>
<tr>
<td>cut_for_search</td>
<td>&#x6CD5;&#x63A5;&#x53D7;&#x4E24;&#x4E2A;&#x53C2;&#x6570;&#xFF1A;&#x9700;&#x8981;&#x5206;&#x8BCD;&#x7684;&#x5B57;&#x7B26;&#x4E32;&#xFF1B;&#x662F;&#x5426;&#x4F7F;&#x7528; HMM &#x6A21;&#x578B;&#x3002;&#x8BE5;&#x65B9;&#x6CD5;&#x9002;&#x5408;&#x7528;&#x4E8E;&#x641C;&#x7D22;&#x5F15;&#x64CE;&#x6784;&#x5EFA;&#x5012;&#x6392;&#x7D22;&#x5F15;&#x7684;&#x5206;&#x8BCD;&#xFF0C;&#x7C92;&#x5EA6;&#x6BD4;&#x8F83;&#x7EC6;</td>
<td>&#x8FD4;&#x56DE;&#x4E00;&#x4E2A;&#x53EF;&#x8FED;&#x4EE3;&#x7684;generator</td>
</tr>
<tr>
<td>Tokenizer(dictionary=DEFAULT_DICT)</td>
<td>&#x65B0;&#x5EFA;&#x81EA;&#x5B9A;&#x4E49;&#x5206;&#x8BCD;&#x5668;&#xFF0C;&#x53EF;&#x7528;&#x4E8E;&#x540C;&#x65F6;&#x4F7F;&#x7528;&#x4E0D;&#x540C;&#x8BCD;&#x5178;&#x3002;jieba.dt &#x4E3A;&#x9ED8;&#x8BA4;&#x5206;&#x8BCD;&#x5668;&#xFF0C;&#x6240;&#x6709;&#x5168;&#x5C40;&#x5206;&#x8BCD;&#x76F8;&#x5173;&#x51FD;&#x6570;&#x90FD;&#x662F;&#x8BE5;&#x5206;&#x8BCD;&#x5668;&#x7684;&#x6620;&#x5C04;&#x3002;</td>
</tr>
</tbody>
</table>
<pre><code class="lang-py"><span class="hljs-comment"># &#x5B98;&#x65B9;&#x4F8B;&#x7A0B;</span>

<span class="hljs-comment"># encoding=utf-8</span>
<span class="hljs-keyword">import</span> jieba

seg_list = jieba.cut(<span class="hljs-string">&quot;&#x6211;&#x6765;&#x5230;&#x5317;&#x4EAC;&#x6E05;&#x534E;&#x5927;&#x5B66;&quot;</span>, cut_all=<span class="hljs-keyword">True</span>)
print(<span class="hljs-string">&quot;Full Mode: &quot;</span> + <span class="hljs-string">&quot;/ &quot;</span>.join(seg_list))
<span class="hljs-comment"># &#x5168;&#x6A21;&#x5F0F;:&#x6211;/ &#x6765;&#x5230;/ &#x5317;&#x4EAC;/ &#x6E05;&#x534E;/ &#x6E05;&#x534E;&#x5927;&#x5B66;/ &#x534E;&#x5927;/ &#x5927;&#x5B66; </span>

seg_list = jieba.cut(<span class="hljs-string">&quot;&#x6211;&#x6765;&#x5230;&#x5317;&#x4EAC;&#x6E05;&#x534E;&#x5927;&#x5B66;&quot;</span>, cut_all=<span class="hljs-keyword">False</span>)
print(<span class="hljs-string">&quot;Default Mode: &quot;</span> + <span class="hljs-string">&quot;/ &quot;</span>.join(seg_list))  
<span class="hljs-comment"># &#x7CBE;&#x786E;&#x6A21;&#x5F0F;:&#x6211;/ &#x6765;&#x5230;/ &#x5317;&#x4EAC;/ &#x6E05;&#x534E;&#x5927;&#x5B66; </span>

seg_list = jieba.cut(<span class="hljs-string">&quot;&#x4ED6;&#x6765;&#x5230;&#x4E86;&#x7F51;&#x6613;&#x676D;&#x7814;&#x5927;&#x53A6;&quot;</span>)  <span class="hljs-comment"># &#x9ED8;&#x8BA4;&#x662F;&#x7CBE;&#x786E;&#x6A21;&#x5F0F;</span>
print(<span class="hljs-string">&quot;, &quot;</span>.join(seg_list))
<span class="hljs-comment"># &#x65B0;&#x8BCD;&#x8BC6;&#x522B;:&#x4ED6;, &#x6765;&#x5230;, &#x4E86;, &#x7F51;&#x6613;, &#x676D;&#x7814;, &#x5927;&#x53A6; (&#x6B64;&#x5904;&#xFF0C;&#x201C;&#x676D;&#x7814;&#x201D;&#x5E76;&#x6CA1;&#x6709;&#x5728;&#x8BCD;&#x5178;&#x4E2D;&#xFF0C;&#x4F46;&#x662F;&#x4E5F;&#x88AB;Viterbi&#x7B97;&#x6CD5;&#x8BC6;&#x522B;&#x51FA;&#x6765;&#x4E86;) </span>

seg_list = jieba.cut_for_search(<span class="hljs-string">&quot;&#x5C0F;&#x660E;&#x7855;&#x58EB;&#x6BD5;&#x4E1A;&#x4E8E;&#x4E2D;&#x56FD;&#x79D1;&#x5B66;&#x9662;&#x8BA1;&#x7B97;&#x6240;&#xFF0C;&#x540E;&#x5728;&#x65E5;&#x672C;&#x4EAC;&#x90FD;&#x5927;&#x5B66;&#x6DF1;&#x9020;&quot;</span>)
print(<span class="hljs-string">&quot;, &quot;</span>.join(seg_list)
<span class="hljs-comment"># &#x641C;&#x7D22;&#x5F15;&#x64CE;&#x6A21;&#x5F0F;&#xFF1A;&#x5C0F;&#x660E;, &#x7855;&#x58EB;, &#x6BD5;&#x4E1A;, &#x4E8E;, &#x4E2D;&#x56FD;, &#x79D1;&#x5B66;, &#x5B66;&#x9662;, &#x79D1;&#x5B66;&#x9662;, &#x4E2D;&#x56FD;&#x79D1;&#x5B66;&#x9662;, &#x8BA1;&#x7B97;, &#x8BA1;&#x7B97;&#x6240;, &#x540E;, &#x5728;, &#x65E5;&#x672C;, &#x4EAC;&#x90FD;, &#x5927;&#x5B66;, &#x65E5;&#x672C;&#x4EAC;&#x90FD;&#x5927;&#x5B66;, &#x6DF1;&#x9020;</span>
</code></pre>
<h2 id="33-&#x5173;&#x952E;&#x8BCD;&#x63D0;&#x53D6;">3.3. &#x5173;&#x952E;&#x8BCD;&#x63D0;&#x53D6;</h2>
<h3 id="331-&#x9ED8;&#x8BA4;&#x5173;&#x952E;&#x8BCD;&#x63D0;&#x53D6;&#x65B9;&#x6CD5;">3.3.1. &#x9ED8;&#x8BA4;&#x5173;&#x952E;&#x8BCD;&#x63D0;&#x53D6;&#x65B9;&#x6CD5;</h3>
<pre><code class="lang-py">text = <span class="hljs-string">&quot; &quot;</span>.join(sentences)
keywords = jieba.analyse.extract_tags(text, topK=result_number, withWeight=<span class="hljs-keyword">True</span>, allowPOS=())
</code></pre>
<ul>
<li><code>jieba.analyse.extract_tags(sentence, topK=20, withWeight=False, allowPOS=())</code><ul>
<li>topK: &#x8F93;&#x51FA;&#x7684;&#x5173;&#x952E;&#x8BCD;&#x6570;&#x91CF;&#xFF0C;&#x5982;&#x679C;&#x662F;None&#x5219;&#x5168;&#x90E8;&#x5173;&#x952E;&#x8BCD;&#x90FD;&#x8F93;&#x51FA;&#xFF1B;</li>
<li>withWeight: &#x8F93;&#x51FA;&#x7684;&#x5173;&#x952E;&#x8BCD;&#x662F;&#x5426;&#x9644;&#x5E26;textrank&#x8BA1;&#x7B97;&#x51FA;&#x6765;&#x7684;&#x6743;&#x91CD;&#x503C;</li>
<li>allowPOS: &#x8BE5;&#x53C2;&#x6570;&#x4E3A;&#x5217;&#x8868;&#xFF0C;&#x8868;&#x793A;&#x4EC5;&#x663E;&#x793A;&#x7B26;&#x5408;&#x8BE5;&#x53C2;&#x6570;&#x8BBE;&#x7F6E;&#x8BCD;&#x6027;&#x7684;&#x5173;&#x952E;&#x8BCD;</li>
<li>withFlag: &#x8F93;&#x51FA;&#x7684;&#x5173;&#x952E;&#x8BCD;&#x662F;&#x5426;&#x9644;&#x5E26;&#x8BCD;&#x6027;</li>
</ul>
</li>
</ul>
<h3 id="332-textrank&#x65B9;&#x6CD5;&#x63D0;&#x53D6;&#x5173;&#x952E;&#x8BCD;">3.3.2. textrank&#x65B9;&#x6CD5;&#x63D0;&#x53D6;&#x5173;&#x952E;&#x8BCD;</h3>
<pre><code class="lang-py">text = <span class="hljs-string">&quot; &quot;</span>.join(sentences)
keywords = jieba.analyse.textrank(text, topK=result_number, withWeight=<span class="hljs-keyword">True</span>, allowPOS=())
</code></pre>
<ul>
<li><p><code>jieba.analyse.textrank(sentence, topK=20, withWeight=False, allowPOS=(&#x2018;ns&#x2019;, &#x2018;n&#x2019;, &#x2018;vn&#x2019;, &#x2018;v&#x2019;))</code></p>
<ul>
<li>topK: &#x8F93;&#x51FA;&#x7684;&#x5173;&#x952E;&#x8BCD;&#x6570;&#x91CF;&#xFF0C;&#x5982;&#x679C;&#x662F;None&#x5219;&#x5168;&#x90E8;&#x5173;&#x952E;&#x8BCD;&#x90FD;&#x8F93;&#x51FA;&#xFF1B;</li>
<li>withWeight: &#x8F93;&#x51FA;&#x7684;&#x5173;&#x952E;&#x8BCD;&#x662F;&#x5426;&#x9644;&#x5E26;textrank&#x8BA1;&#x7B97;&#x51FA;&#x6765;&#x7684;&#x6743;&#x91CD;&#x503C;</li>
<li>allowPOS: &#x8BE5;&#x53C2;&#x6570;&#x4E3A;&#x5217;&#x8868;&#xFF0C;&#x8868;&#x793A;&#x4EC5;&#x663E;&#x793A;&#x7B26;&#x5408;&#x8BE5;&#x53C2;&#x6570;&#x8BBE;&#x7F6E;&#x8BCD;&#x6027;&#x7684;&#x5173;&#x952E;&#x8BCD;</li>
<li>withFlag: &#x8F93;&#x51FA;&#x7684;&#x5173;&#x952E;&#x8BCD;&#x662F;&#x5426;&#x9644;&#x5E26;&#x8BCD;&#x6027;</li>
</ul>
</li>
<li><p>&#x7B97;&#x6CD5;&#x6838;&#x5FC3;&#x662F;&#x5C06;&#x6587;&#x672C;&#x56FE;&#x5316;</p>
</li>
<li>TextRank&#x76F8;&#x8F83;&#x4E8E;TFIDF&#xFF0C;&#x66F4;&#x4F9D;&#x8D56;&#x5206;&#x8BCD;&#x7ED3;&#x679C;&#xFF0C;&#x5982;&#x679C;&#x5206;&#x8BCD;&#x8FC7;&#x7A0B;&#x4E2D;&#xFF0C;&#x67D0;&#x4E9B;&#x5173;&#x952E;&#x8BCD;&#x88AB;&#x5207;&#x5206;&#x4E86;&#xFF0C;&#x5C31;&#x4F1A;&#x5F97;&#x5230;&#x4E0D;&#x540C;&#x7684;&#x7ED3;&#x679C;&#xFF0C;&#x6240;&#x4EE5;&#x5DE5;&#x4E1A;&#x5E94;&#x7528;&#x65F6;&#xFF0C;&#x4F1A;&#x5C06;&#x90E8;&#x5206;&#x5207;&#x5206;&#x7684;&#x5173;&#x952E;&#x8BCD;&#x8FDB;&#x884C;&#x5408;&#x5E76;&#x3002;</li>
</ul>
<blockquote>
<p><a href="https://www.cnblogs.com/xueyinzhe/p/7101295.html" target="_blank">TextRank&#x7B97;&#x6CD5;&#x539F;&#x7406;</a></p>
</blockquote>
<h3 id="333-tfidf&#x7684;&#x65B9;&#x6CD5;&#x63D0;&#x53D6;&#x5173;&#x952E;&#x8BCD;">3.3.3. tfidf&#x7684;&#x65B9;&#x6CD5;&#x63D0;&#x53D6;&#x5173;&#x952E;&#x8BCD;</h3>
<pre><code class="lang-py">text = <span class="hljs-string">&quot; &quot;</span>.join(sentences)
keywords = jieba.analyse.tfidf(text, topK=result_number, withWeight=<span class="hljs-keyword">True</span>, allowPOS=())
</code></pre>
<blockquote>
<p><a href="https://blog.csdn.net/zrc199021/article/details/53728499" target="_blank">TF-IDF&#x539F;&#x7406;&#x53CA;&#x4F7F;&#x7528;</a></p>
</blockquote>
<h2 id="34-&#x8BCD;&#x5F62;&#x6807;&#x6CE8;">3.4. &#x8BCD;&#x5F62;&#x6807;&#x6CE8;</h2>
<ol>
<li>&#x81EA;&#x5B9A;&#x4E49;&#x5206;&#x8BCD;&#x5668;:<code>jieba.posseg.POSTokenizer(tokenizer=None)</code></li>
<li>&#x6807;&#x6CE8;&#x53E5;&#x5B50;&#x5206;&#x8BCD;&#x540E;&#x6BCF;&#x4E2A;&#x8BCD;&#x7684;&#x8BCD;&#x5F62;&#xFF0C;&#x91C7;&#x7528;&#x548C;ictclas&#x517C;&#x5BB9;&#x7684;&#x6807;&#x8BB0;&#x6CD5;&#x3002;</li>
</ol>
<pre><code class="lang-py"><span class="hljs-comment"># &#x5B98;&#x65B9;&#x4F8B;&#x7A0B;</span>
<span class="hljs-keyword">import</span> jieba.posseg <span class="hljs-keyword">as</span> pseg

words = pseg.cut(<span class="hljs-string">&quot;&#x6211;&#x7231;&#x5317;&#x4EAC;&#x5929;&#x5B89;&#x95E8;&quot;</span>)
<span class="hljs-comment"># words&#x7C7B;&#x522B;&#x4E3A;&#xFF1A;generator</span>

<span class="hljs-keyword">for</span> word, flag <span class="hljs-keyword">in</span> words:
    print(<span class="hljs-string">&apos;%s %s&apos;</span> % (word, flag))

<span class="hljs-comment"># &#x6211; r </span>
<span class="hljs-comment"># &#x7231; v </span>
<span class="hljs-comment"># &#x5317;&#x4EAC; ns </span>
<span class="hljs-comment"># &#x5929;&#x5B89;&#x95E8; ns</span>
</code></pre>
<h1 id="4-&#x6587;&#x672C;&#x5173;&#x952E;&#x8BCD;&#x63D0;&#x53D6;&#x4F7F;&#x7528;rake-nltk">4. &#x6587;&#x672C;&#x5173;&#x952E;&#x8BCD;&#x63D0;&#x53D6;(&#x4F7F;&#x7528;rake-nltk)</h1>
<ol>
<li>rake&#x662F;&#x4E00;&#x4E2A;&#x57FA;&#x4E8E;nltk&#x7684;&#x5FEB;&#x901F;&#x81EA;&#x52A8;&#x5173;&#x952E;&#x8BCD;&#x63D0;&#x53D6;&#x7B97;&#x6CD5;</li>
</ol>
<pre><code class="lang-py"><span class="hljs-keyword">from</span> rake_nltk <span class="hljs-keyword">import</span> Rake
<span class="hljs-keyword">from</span> rake_nltk <span class="hljs-keyword">import</span> Metric

r = Rake(max_length = result_number)
text = <span class="hljs-string">&quot; &quot;</span>.join(sentences)
r.extract_keywords_from_text(text)

keywords = r.get_ranked_phrases_with_scores()
</code></pre>
<h1 id="5-&#x6587;&#x672C;&#x9884;&#x5904;&#x7406;&#x548C;&#x5173;&#x952E;&#x8BCD;&#x5904;&#x7406;&#x7684;&#x5B8C;&#x6574;&#x4EE3;&#x7801;">5. &#x6587;&#x672C;&#x9884;&#x5904;&#x7406;&#x548C;&#x5173;&#x952E;&#x8BCD;&#x5904;&#x7406;&#x7684;&#x5B8C;&#x6574;&#x4EE3;&#x7801;</h1>
<pre><code class="lang-py"><span class="hljs-comment"># -*- coding: utf-8 -*-</span>

<span class="hljs-keyword">import</span> os
<span class="hljs-keyword">import</span> re
<span class="hljs-keyword">import</span> collections
<span class="hljs-keyword">from</span> nltk <span class="hljs-keyword">import</span> word_tokenize, pos_tag
<span class="hljs-keyword">from</span> nltk.corpus <span class="hljs-keyword">import</span> wordnet
<span class="hljs-keyword">from</span> nltk.stem <span class="hljs-keyword">import</span> WordNetLemmatizer
<span class="hljs-keyword">import</span> jieba.analyse
<span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm
<span class="hljs-keyword">import</span> random
<span class="hljs-keyword">from</span> rake_nltk <span class="hljs-keyword">import</span> Rake
<span class="hljs-keyword">from</span> rake_nltk <span class="hljs-keyword">import</span> Metric

result_number = <span class="hljs-number">50</span>

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">extractKeyWords</span>:</span>

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self, save_path)</span>:</span>
        <span class="hljs-string">&apos;&apos;&apos;
        &#x521D;&#x59CB;&#x5316;&#x5173;&#x952E;&#x8BCD;&#x63D0;&#x53D6;&#x5668;
        :param save_path: &#x4FDD;&#x5B58;&#x8DEF;&#x5F84;
        &apos;&apos;&apos;</span>
        self.save_path = save_path
        self.sentences = []
        <span class="hljs-comment"># stemmer = SnowballStemmer(&quot;english&quot;)</span>
        words = []
        stopwords = []
        <span class="hljs-comment"># &#x52A0;&#x8F7D;&#x505C;&#x7528;&#x8BCD;</span>
        <span class="hljs-keyword">with</span> open(<span class="hljs-string">&quot;./stopwords.txt&quot;</span> , <span class="hljs-string">&quot;r&quot;</span>, encoding=<span class="hljs-string">&quot;utf-8&quot;</span>) <span class="hljs-keyword">as</span> f:
            <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> f.readlines():
                stopwords.append(line.strip())
        print(<span class="hljs-string">&quot;Load Finish! Begin preprocess!&quot;</span>)
        <span class="hljs-comment"># &#x5BF9;&#x6BCF;&#x4E00;&#x4E2A;&#x8BCD;&#x8FDB;&#x884C;&#x5904;&#x7406;</span>
        <span class="hljs-keyword">for</span> ACL2020 <span class="hljs-keyword">in</span> tqdm(os.listdir(<span class="hljs-string">&quot;./ACL2020_txt&quot;</span>)):
            <span class="hljs-keyword">with</span> open(<span class="hljs-string">&quot;./ACL2020_txt/&quot;</span> + ACL2020, <span class="hljs-string">&apos;r&apos;</span>, encoding=<span class="hljs-string">&quot;utf-8&quot;</span>) <span class="hljs-keyword">as</span> f:
                <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> f.readlines():
                    <span class="hljs-comment"># &#x53BB;&#x9664;&#x5927;&#x5C0F;&#x5199;</span>
                    line = line.lower()
                    <span class="hljs-comment"># &#x53BB;&#x9664;&#x7279;&#x6B8A;&#x5B57;&#x7B26;</span>
                    line = re.sub(<span class="hljs-string">&apos;[\W_]+&apos;</span>, <span class="hljs-string">&quot; &quot;</span>, line)
                    <span class="hljs-comment"># &#x53BB;&#x9664;&#x6570;&#x5B57;</span>
                    line = re.sub(<span class="hljs-string">&apos;[0-9]&apos;</span>, <span class="hljs-string">&quot; &quot;</span>, line)
                    <span class="hljs-comment"># &#x6392;&#x9664;&#x5E38;&#x7528;&#x4E2D;&#x6587;&#x5B57;&#x7B26;</span>
                    line = re.sub(<span class="hljs-string">r&apos;[\u4e00-\u9fa5]&apos;</span>, <span class="hljs-string">&quot;&quot;</span>, line)

                    temp_words = word_tokenize(line)
                    <span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> temp_words:
                        <span class="hljs-keyword">if</span> word <span class="hljs-keyword">in</span> stopwords:
                            <span class="hljs-keyword">continue</span>
                        words.append(word)
        <span class="hljs-comment"># &#x83B7;&#x53D6;&#x5355;&#x8BCD;&#x8BCD;&#x6027;</span>
        tags = pos_tag(words)

        <span class="hljs-comment"># &#x4F7F;&#x7528;WordNetLemmatizer&#x8FDB;&#x884C;&#x8BCD;&#x5F62;&#x8FD8;&#x539F;</span>
        wnl = WordNetLemmatizer()
        lemmas_sent = []
        <span class="hljs-keyword">for</span> tag <span class="hljs-keyword">in</span> tags:
            wordnet_pos = self._get_wordnet_pos(tag[<span class="hljs-number">1</span>]) <span class="hljs-keyword">or</span> wordnet.NOUN
            lemmas_sent.append(wnl.lemmatize(tag[<span class="hljs-number">0</span>], pos=wordnet_pos))  <span class="hljs-comment"># &#x8BCD;&#x5F62;&#x8FD8;&#x539F;</span>
        self.sentences.append(<span class="hljs-string">&quot; &quot;</span>.join(lemmas_sent))
        print(<span class="hljs-string">&quot;preprocess finish!&quot;</span>)

    <span class="hljs-comment"># &#x83B7;&#x53D6;&#x5355;&#x8BCD;&#x7684;&#x8BCD;&#x6027;</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">_get_wordnet_pos</span><span class="hljs-params">(self, tag)</span>:</span>
        <span class="hljs-string">&apos;&apos;&apos;
        &#x6839;&#x636E;tag&#x6765;&#x83B7;&#x53D6;&#x8BCD;&#x6027;
        :param tag:
        :return:
        &apos;&apos;&apos;</span>
        <span class="hljs-keyword">if</span> tag.startswith(<span class="hljs-string">&apos;J&apos;</span>):
            <span class="hljs-keyword">return</span> wordnet.ADJ
        <span class="hljs-keyword">elif</span> tag.startswith(<span class="hljs-string">&apos;V&apos;</span>):
            <span class="hljs-keyword">return</span> wordnet.VERB
        <span class="hljs-keyword">elif</span> tag.startswith(<span class="hljs-string">&apos;N&apos;</span>):
            <span class="hljs-keyword">return</span> wordnet.NOUN
        <span class="hljs-keyword">elif</span> tag.startswith(<span class="hljs-string">&apos;R&apos;</span>):
            <span class="hljs-keyword">return</span> wordnet.ADV
        <span class="hljs-keyword">else</span>:
            <span class="hljs-keyword">return</span> <span class="hljs-keyword">None</span>

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">run</span><span class="hljs-params">(self)</span>:</span>
        self.method_1()
        self.method_2()
        self.method_3()
        self.method_4()
        self.method_5()
        self.method_6()
        self.method_7()

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">method_1</span><span class="hljs-params">(self)</span>:</span>
        <span class="hljs-string">&apos;&apos;&apos;
        &#x4F7F;&#x7528;&#x6743;&#x91CD;
        :return:
        &apos;&apos;&apos;</span>
        <span class="hljs-comment"># &#x5BF9;&#x6BCF;&#x4E2A;&#x53E5;&#x5B50;&#x8FDB;&#x884C;&#x5206;&#x8BCD;</span>
        print(<span class="hljs-string">&quot;method1 begin!&quot;</span>)
        sentences = [word_tokenize(sentences) <span class="hljs-keyword">for</span> sentences <span class="hljs-keyword">in</span> self.sentences]
        words = []
        <span class="hljs-keyword">for</span> sentence <span class="hljs-keyword">in</span> sentences:
            <span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> sentence:
                words.append(word)
        total = len(words)
        counter = collections.Counter(words)
        result = []
        <span class="hljs-keyword">for</span> temp <span class="hljs-keyword">in</span> counter.most_common(result_number):
            temp = list(temp)
            temp[<span class="hljs-number">1</span>] = temp[<span class="hljs-number">1</span>]/total
            result.append(temp)
        self.write2file(result, <span class="hljs-string">&quot;method1_dic.txt&quot;</span>)
        print(<span class="hljs-string">&quot;method1 finish!&quot;</span>)

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">method_2</span><span class="hljs-params">(self)</span>:</span>
        <span class="hljs-string">&apos;&apos;&apos;
        &#x4F7F;&#x7528;jieba&#x5206;&#x8BCD;&#x7684;extract_tags&#x7684;&#x65B9;&#x6CD5;&#x8FDB;&#x884C;&#x8FD0;&#x7B97;
        :return:
        &apos;&apos;&apos;</span>
        print(<span class="hljs-string">&quot;method2 begin!&quot;</span>)
        text = <span class="hljs-string">&quot; &quot;</span>.join(self.sentences)

        keywords = jieba.analyse.extract_tags(text, topK=result_number, withWeight=<span class="hljs-keyword">True</span>, allowPOS=())
        self.write2file(keywords, <span class="hljs-string">&quot;method2_dic.txt&quot;</span>)
        print(<span class="hljs-string">&quot;method2 finish!&quot;</span>)

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">method_3</span><span class="hljs-params">(self)</span>:</span>
        <span class="hljs-string">&apos;&apos;&apos;
        &#x4F7F;&#x7528;&#x968F;&#x673A;&#x7684;&#x65B9;&#x6CD5;&#xFF0C;&#x968F;&#x673A;&#x9009;&#x62E9;result_number&#x4E2A;&#x5173;&#x952E;&#x8BCD;
        :return:
        &apos;&apos;&apos;</span>
        print(<span class="hljs-string">&quot;method3 begin!&quot;</span>)
        sentences = [word_tokenize(sentences) <span class="hljs-keyword">for</span> sentences <span class="hljs-keyword">in</span> self.sentences]
        words = []
        <span class="hljs-keyword">for</span> sentence <span class="hljs-keyword">in</span> sentences:
            <span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> sentence:
                words.append(word)
        total = len(words)
        <span class="hljs-comment"># &#x968F;&#x673A;&#x83B7;&#x53D6;result_number&#x4E2A;&#x5143;&#x7D20;</span>
        numbers = []
        <span class="hljs-keyword">while</span> len(numbers) &lt;= result_number:
            number = random.randint(<span class="hljs-number">0</span>, total - <span class="hljs-number">1</span>)
            <span class="hljs-keyword">if</span> number <span class="hljs-keyword">in</span> numbers:
                <span class="hljs-keyword">continue</span>
            numbers.append(number)
        counter = collections.Counter(words)
        result = []
        <span class="hljs-keyword">for</span> number <span class="hljs-keyword">in</span> numbers:
            result.append([words[number], counter[words[number]] / total])
        <span class="hljs-comment"># &#x964D;&#x5E8F;&#x8F93;&#x51FA;</span>
        result.sort(key=<span class="hljs-keyword">lambda</span> x: x[<span class="hljs-number">1</span>], reverse=<span class="hljs-keyword">True</span>)
        self.write2file(result, <span class="hljs-string">&quot;method3_dic.txt&quot;</span>)
        print(<span class="hljs-string">&quot;method3 finish!&quot;</span>)

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">method_4</span><span class="hljs-params">(self)</span>:</span>
        <span class="hljs-string">&apos;&apos;&apos;
        &#x4F7F;&#x7528;jieba&#x5206;&#x8BCD;&#x7684;tfidf&#x65B9;&#x6CD5;&#x83B7;&#x53D6;&#x5173;&#x952E;&#x8BCD;
        :return:
        &apos;&apos;&apos;</span>
        print(<span class="hljs-string">&quot;method4 begin!&quot;</span>)
        text = <span class="hljs-string">&quot; &quot;</span>.join(self.sentences)

        keywords = jieba.analyse.tfidf(text, topK=result_number, withWeight=<span class="hljs-keyword">True</span>, allowPOS=())
        self.write2file(keywords, <span class="hljs-string">&quot;method4_dic.txt&quot;</span>)
        print(<span class="hljs-string">&quot;method4 finish!&quot;</span>)

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">method_5</span><span class="hljs-params">(self)</span>:</span>
        <span class="hljs-string">&apos;&apos;&apos;
        &#x4F7F;&#x7528;&#x76F8;&#x5BF9;&#x66F4;&#x52A0;&#x5FEB;&#x901F;&#x7684;rake&#x7B97;&#x6CD5;,&#x4F7F;&#x7528;&#x9ED8;&#x8BA4;&#x77E9;&#x9635;&#x6765;&#x8FDB;&#x884C;&#x5173;&#x952E;&#x8BCD;&#x63D0;&#x53D6;
        :return:
        &apos;&apos;&apos;</span>
        print(<span class="hljs-string">&quot;method5 begin!&quot;</span>)
        r = Rake(max_length = result_number)
        text = <span class="hljs-string">&quot; &quot;</span>.join(self.sentences)
        r.extract_keywords_from_text(text)

        keywords = r.get_ranked_phrases_with_scores()

        <span class="hljs-comment"># &#x6807;&#x51C6;&#x5316;&#x8F93;&#x51FA;</span>
        result = []
        head = []
        <span class="hljs-keyword">for</span> keyword <span class="hljs-keyword">in</span> keywords:
            <span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> keyword[<span class="hljs-number">1</span>].split(<span class="hljs-string">&quot; &quot;</span>):
                <span class="hljs-keyword">if</span>(word <span class="hljs-keyword">in</span> head):
                    <span class="hljs-keyword">continue</span>
                result.append([word, keyword[<span class="hljs-number">0</span>]])
                head.append(word)
                <span class="hljs-keyword">if</span>(len(head) &gt;= result_number):
                    <span class="hljs-keyword">break</span>
            <span class="hljs-keyword">if</span> (len(head) &gt;= result_number):
                <span class="hljs-keyword">break</span>
        self.write2file(result, <span class="hljs-string">&quot;method5_dic.txt&quot;</span>)
        print(<span class="hljs-string">&quot;method5 finish!&quot;</span>)

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">method_6</span><span class="hljs-params">(self)</span>:</span>
        <span class="hljs-string">&apos;&apos;&apos;
        &#x4F7F;&#x7528;&#x76F8;&#x5BF9;&#x66F4;&#x52A0;&#x5FEB;&#x901F;&#x7684;rake&#x7B97;&#x6CD5;,&#x4F7F;&#x7528;&#x8BCD;&#x9891;&#x77E9;&#x9635;&#x6765;&#x8FDB;&#x884C;&#x5173;&#x952E;&#x8BCD;&#x63D0;&#x53D6;
        :return:
        &apos;&apos;&apos;</span>
        print(<span class="hljs-string">&quot;method6 begin!&quot;</span>)
        r = Rake(max_length = result_number, ranking_metric = Metric.WORD_FREQUENCY)
        text = <span class="hljs-string">&quot; &quot;</span>.join(self.sentences)
        r.extract_keywords_from_text(text)

        keywords = r.get_ranked_phrases_with_scores()

        <span class="hljs-comment"># &#x6807;&#x51C6;&#x5316;&#x8F93;&#x51FA;</span>
        result = []
        head = []
        <span class="hljs-keyword">for</span> keyword <span class="hljs-keyword">in</span> keywords:
            <span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> keyword[<span class="hljs-number">1</span>].split(<span class="hljs-string">&quot; &quot;</span>):
                <span class="hljs-keyword">if</span>(word <span class="hljs-keyword">in</span> head):
                    <span class="hljs-keyword">continue</span>
                result.append([word, keyword[<span class="hljs-number">0</span>]])
                head.append(word)
                <span class="hljs-keyword">if</span>(len(head) &gt;= result_number):
                    <span class="hljs-keyword">break</span>
            <span class="hljs-keyword">if</span> (len(head) &gt;= result_number):
                <span class="hljs-keyword">break</span>
        self.write2file(result, <span class="hljs-string">&quot;method6_dic.txt&quot;</span>)
        print(<span class="hljs-string">&quot;method6 finish!&quot;</span>)

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">method_7</span><span class="hljs-params">(self)</span>:</span>
        <span class="hljs-string">&apos;&apos;&apos;
        &#x4F7F;&#x7528;&#x76F8;&#x5BF9;&#x66F4;&#x52A0;&#x5FEB;&#x901F;&#x7684;rake&#x7B97;&#x6CD5;,&#x4F7F;&#x7528;&#x8BCD;&#x7EA7;&#x77E9;&#x9635;&#x6765;&#x8FDB;&#x884C;&#x5173;&#x952E;&#x8BCD;&#x63D0;&#x53D6;
        :return:
        &apos;&apos;&apos;</span>
        print(<span class="hljs-string">&quot;method6 begin!&quot;</span>)
        r = Rake(max_length=result_number, ranking_metric=Metric.WORD_DEGREE)
        text = <span class="hljs-string">&quot; &quot;</span>.join(self.sentences)
        r.extract_keywords_from_text(text)

        keywords = r.get_ranked_phrases_with_scores()

        <span class="hljs-comment"># &#x6807;&#x51C6;&#x5316;&#x8F93;&#x51FA;</span>
        result = []
        head = []
        <span class="hljs-keyword">for</span> keyword <span class="hljs-keyword">in</span> keywords:
            <span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> keyword[<span class="hljs-number">1</span>].split(<span class="hljs-string">&quot; &quot;</span>):
                <span class="hljs-keyword">if</span> (word <span class="hljs-keyword">in</span> head):
                    <span class="hljs-keyword">continue</span>
                result.append([word, keyword[<span class="hljs-number">0</span>]])
                head.append(word)
                <span class="hljs-keyword">if</span> (len(head) &gt;= result_number):
                    <span class="hljs-keyword">break</span>
            <span class="hljs-keyword">if</span> (len(head) &gt;= result_number):
                <span class="hljs-keyword">break</span>
        self.write2file(result, <span class="hljs-string">&quot;method7_dic.txt&quot;</span>)
        print(<span class="hljs-string">&quot;method7 finish!&quot;</span>)

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">write2file</span><span class="hljs-params">(self, keywords, save_path)</span>:</span>
        <span class="hljs-string">&apos;&apos;&apos;
        &#x5C06;&#x5173;&#x952E;&#x8BCD;&#x5237;&#x65B0;&#x5230;&#x6307;&#x5B9A;&#x6587;&#x4EF6;&#x4E2D;
        :param keywords: (words, weight) &#x7684;&#x5217;&#x8868;
        :param save_path: &#x4FDD;&#x5B58;&#x7684;&#x6587;&#x4EF6;&#x76EE;&#x5F55;
        :return:
        &apos;&apos;&apos;</span>
        <span class="hljs-keyword">with</span> open(os.path.join(self.save_path, save_path), <span class="hljs-string">&apos;w&apos;</span>, encoding=<span class="hljs-string">&quot;utf-8&quot;</span>) <span class="hljs-keyword">as</span> f:
            <span class="hljs-keyword">for</span> keyword <span class="hljs-keyword">in</span> keywords:
                f.write(str(keyword[<span class="hljs-number">0</span>]) + <span class="hljs-string">&quot;\t&quot;</span> + str(keyword[<span class="hljs-number">1</span>]) + <span class="hljs-string">&quot;\n&quot;</span>)

<span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&apos;__main__&apos;</span>:
    tmp = extractKeyWords(<span class="hljs-string">&quot;./result&quot;</span>)
    tmp.run()
</code></pre>
<h1 id="6-&#x53C2;&#x8003;">6. &#x53C2;&#x8003;</h1>
<ol>
<li><a href="https://www.cnblogs.com/jclian91/p/9898511.html" target="_blank">NLP&#x5165;&#x95E8;&#xFF08;&#x4E09;&#xFF09;&#x8BCD;&#x5F62;&#x8FD8;&#x539F;&#xFF08;Lemmatization&#xFF09;</a></li>
<li><a href="https://blog.csdn.net/weixin_39712314/article/details/106173356" target="_blank">nltk_data LookupError: Resource punkt not found. Please use the NLTK Downloader to obtain the resour</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/161342541" target="_blank">&#x7528;Python&#x7ED9;&#x4F60;&#x7684;&#x6587;&#x672C;&#x63D0;&#x53D6;&#x5173;&#x952E;&#x8BCD;</a></li>
<li><a href="https://blog.csdn.net/bozhanggu2239/article/details/80157305" target="_blank">Python&#x7684;jieba&#x5206;&#x8BCD;&#x53CA;TF-IDF&#x548C;TextRank &#x7B97;&#x6CD5;&#x63D0;&#x53D6;&#x5173;&#x952E;&#x5B57;</a></li>
<li><a href="https://php.ctolib.com/rake-nltk.html" target="_blank">rake-nltk&#xFF1A;Python&#x5B9E;&#x73B0;&#x4F7F;&#x7528;NLTK&#x7684;&#x5FEB;&#x901F;&#x81EA;&#x52A8;&#x5173;&#x952E;&#x5B57;&#x63D0;&#x53D6;&#x7B97;&#x6CD5;</a></li>
</ol>

                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                <a href="Tec5-pdfminer.html" class="navigation navigation-prev " aria-label="Previous page: Tec5-pdfminer">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
                <a href="Tec7-图片处理.html" class="navigation navigation-next " aria-label="Next page: Tec7-图片处理">
                    <i class="fa fa-angle-right"></i>
                </a>
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"Tec6-文本预处理与关键词提取","level":"1.20","depth":1,"next":{"title":"Tec7-图片处理","level":"1.21","depth":1,"path":"Tec7-图片处理.md","ref":"Tec7-图片处理.md","articles":[]},"previous":{"title":"Tec5-pdfminer","level":"1.19","depth":1,"path":"Tec5-pdfminer.md","ref":"Tec5-pdfminer.md","articles":[]},"dir":"ltr"},"config":{"gitbook":"*","theme":"default","variables":{},"plugins":[],"pluginsConfig":{"highlight":{},"search":{},"lunr":{"maxIndexSize":1000000,"ignoreSpecialCharacters":false},"sharing":{"facebook":true,"twitter":true,"google":false,"weibo":false,"instapaper":false,"vk":false,"all":["facebook","google","twitter","weibo","instapaper"]},"fontsettings":{"theme":"white","family":"sans","size":2},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false}},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"pdf":{"pageNumbers":true,"fontSize":12,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56}},"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"}},"file":{"path":"Tec6-文本预处理与关键词提取.md","mtime":"2020-10-07T06:14:25.042Z","type":"markdown"},"gitbook":{"version":"3.2.3","time":"2020-11-15T13:51:54.635Z"},"basePath":".","book":{"language":""}});
        });
    </script>
</div>

        
    <script src="gitbook/gitbook.js"></script>
    <script src="gitbook/theme.js"></script>
    
        
        <script src="gitbook/gitbook-plugin-search/search-engine.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-search/search.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-lunr/lunr.min.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-lunr/search-lunr.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-sharing/buttons.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-fontsettings/fontsettings.js"></script>
        
    

    </body>
</html>

